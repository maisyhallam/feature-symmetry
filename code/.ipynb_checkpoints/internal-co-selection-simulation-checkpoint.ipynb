{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12a01aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # for writing dataframes to csv\n",
    "import random # for making a random choice\n",
    "import os # for scanning directories\n",
    "import itertools\n",
    "import string # for generating strings\n",
    "\n",
    "import kintypes as kt # bringing large lists of kin types into the namespace\n",
    "import math # for calculating logs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a854cf",
   "metadata": {},
   "source": [
    "# Internal co-selection\n",
    "\n",
    "Internal co-selection refers to the tendency for kinship systems to have cross-generational consistency in the terminological distinctions or mergers that are made. That is, if your parents' elder brothers share a kin term, then so too will their children. If your parents' sisters are distinguished from your parents' brothers, so too will their children be distinguished. We can test the robustness of this tendency using our frankenlanguages, to see whether internal co-selection occurs at a higher rate than chance.\n",
    "\n",
    "We will measure internal co-selection in terms of the **mutual information** between Generation N and Generation N+1 in a particular kinship system. That tells us how much information can be gained from one generation by observing the other - we can think of this as the benefit of internal co-selection. That is, we need to work out the conditional entropy between every possible pair of parent and child terms, and the entropy over an entire generation. This will tell us how much information is shared across the two generations; or how much we can predict about one generation given the other.\n",
    "\n",
    "To do this, we need to do the following:\n",
    "\n",
    "* Get a list of parent-child pairs for each language.\n",
    "* Work out the conditional probabilities for each pair.\n",
    "* Work out the probabilities of each individual term in a generation.\n",
    "* Calculate the entropy of 2 and 3.\n",
    "* Calculate the mutual information of the system.\n",
    "\n",
    "Luckily, we can re-use some of the infrastructure we already have. For ease, I will write out again the functions that extract kin terms from a kinbank file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a list of all the kinbank filenames\n",
    "\n",
    "def get_kb_files():\n",
    "    files = []\n",
    "    path = '../languages/kinbank'\n",
    "    directory = os.scandir(path)\n",
    "    for file in directory:\n",
    "        files.append(file.name)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20247ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to pick a file at random\n",
    "\n",
    "def random_language(all_data):\n",
    "    language = random.choice(all_data)\n",
    "    # print(language)\n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ea0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract kin terms from one of those files\n",
    "\n",
    "def get_kin_terms(filepath):\n",
    "    kin_system = {}\n",
    "    with open(filepath, encoding='utf8') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        next(csv_reader) # to skip the header row\n",
    "        for line in csv_reader:\n",
    "            kin_type = line['parameter']\n",
    "            kin_term = line['word']\n",
    "            kin_system[kin_type] = kin_term\n",
    "    return kin_system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef698b",
   "metadata": {},
   "source": [
    "For testing purposes throughout this notebook, let's pick a random language and extract its kin terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kb_files = get_kb_files()\n",
    "\n",
    "random.seed(47)\n",
    "file = random_language(all_kb_files)\n",
    "filepath = '../languages/kinbank/'\n",
    "\n",
    "l = get_kin_terms(filepath + file)\n",
    "\n",
    "print(file,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93db58b",
   "metadata": {},
   "source": [
    "## Getting the pairs\n",
    "\n",
    "~~The first thing we need to do is write a function that takes a dictionary of kin terms like `l`, and outputs a list of the relevant terms for each generation. We also need a function that pairs up those terms into parent-child pairs. In `kintypes`, we have a list of pairs of codes for parent and child terms, so we just need to cross reference these.~~\n",
    "\n",
    "To avoid weird gaps, we're going to slightly simplify things! First, we're going to extract the relevant pairs of terms from a dictionary of kin terms - e.g. for English, it extracts the pair `('uncle','cousin')`. Notably, our function checks whether **both** of the relevant terms exist in the dictionary before trying to extract them! Then, we'll split these pairs in half to get the list of terms in each generation. This way, any gaps in the kinbank data - e.g. the term for 'uncle' is there, but the term for 'cousin' is not - cause us less strife, at the expense of a little bit of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_generations(ks):\n",
    "#     N = []\n",
    "#     N1 = []\n",
    "#     for kin_type in ks:\n",
    "#         if kin_type in kt.generation_n:\n",
    "#             N.append(ks[kin_type])\n",
    "#         elif kin_type in kt.generation_n1:\n",
    "#             N1.append(ks[kin_type])\n",
    "#         else:\n",
    "#             pass\n",
    "    \n",
    "#     return list(set(N)), list(set(N1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(ks,pairs):\n",
    "    pairs_of_terms = []\n",
    "    placeholder = [] \n",
    "    for pair in pairs:\n",
    "        if pair[0] in ks and pair[1] in ks:\n",
    "            if pair in placeholder:\n",
    "                pass\n",
    "            else:\n",
    "#             print(pair[0],pair[1])\n",
    "                pairs_of_terms.append((ks[pair[0]],ks[pair[1]]))\n",
    "                placeholder.append(pair)\n",
    "            \n",
    "    return pairs_of_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_pairs = get_pairs(l,kt.ics_pairs)\n",
    "\n",
    "print(l_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120705f",
   "metadata": {},
   "source": [
    "Now we have a way to get a list of pairs, let's split them up into `GN` for Ego's generation and `GN1` for ego's parents' generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb59084",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_generations(pairs):\n",
    "    GN = []\n",
    "    GN1 = []\n",
    "    for pair in pairs:\n",
    "        GN.append(pair[1])\n",
    "        GN1.append(pair[0])\n",
    "    \n",
    "    return GN,GN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d259ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_GN, l_GN1 = split_generations(l_pairs)\n",
    "\n",
    "print(l_GN,l_GN1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1877a",
   "metadata": {},
   "source": [
    "## Calculating probabilities\n",
    "\n",
    "To calculate entropy of one generation of a kinship system, we will need to calculate the probability distribution of the terms in that generation. To calculate conditional entropy, we will need a probability distribution for all the pairs of terms in the kinship system. Below is a function that takes a list of elements and calculates the probability of each of those elements w.r.t. the others - those elements can be terms or pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probs(things_that_vary):\n",
    "    probs = []\n",
    "    for thing in set(things_that_vary):\n",
    "        probs.append(things_that_vary.count(thing)/len(things_that_vary))\n",
    "        #print('probability of ', thing, ' is ', things_that_vary.count(thing)/len(things_that_vary))\n",
    "    #print(sum(probs))\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x: str, dataset: list) -> float:\n",
    "    return dataset.count(x)/len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e433cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_probs = calculate_probs(l_GN1)\n",
    "\n",
    "print(l_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99490ea7",
   "metadata": {},
   "source": [
    "We can use this function to calculate the conditional probability of each term given the term it is paired with: the probability of the pair (given all the possible pairs) over the probability of the \"given\" term. Let's do this \"bottom-up\" for ease - so for English, calculating the probability of *uncle* given *cousin*. Since mutual information is not directional, we can make this arbitrary choice without repercussions later.\n",
    "\n",
    "~~Reader, there were repercussions. In my first pass, I got it the wrong way around! Ack.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_conditional_probs(pairs,terms):\n",
    "    cond_probs = []\n",
    "    probs = calculate_probs(terms)\n",
    "#     print(terms)\n",
    "#     print(probs)\n",
    "    \n",
    "    for pair in set(pairs): # for each unique pair\n",
    "        p_pair = pairs.count(pair)/len(pairs) # calculate the probability of the pair\n",
    "        # term_index = list(set(terms)).index(pair[0]) # get the index of the parent term in the terms list\n",
    "        term_index = list(set(terms)).index(pair[1]) # for testing!!!\n",
    "        p_term = probs[term_index] # then use that index to get the probability of that term from probs!\n",
    "        cond_probs.append(p_pair/p_term) # the probability of the pair (B and A) over the probability of the parent term (B) gives us the conditional probability of child given parent\n",
    "        # print('pair: ', pair, 'p(', pair[1], '|', pair[0], ') = ', p_pair/p_term)\n",
    "        # print('pair: ', pair, 'p(', pair[0], '|', pair[1], ') = ', p_pair/p_term)\n",
    "        \n",
    "    return cond_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db26c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d66227",
   "metadata": {},
   "source": [
    "## Calculating entropy and mutual information\n",
    "\n",
    "Now that we have a way to extract probability distributions from a kinship system, we can feed that in to a function that calculates entropy. The entropy scores can then be fed to a function that calculates mutual information (equations to follow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    entropy = 0\n",
    "    for p in probs:\n",
    "        if p != 0:\n",
    "            #entropy += p*math.log2(p)\n",
    "            entropy += p*math.log(p)\n",
    "\n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac4a02",
   "metadata": {},
   "source": [
    "If we feed in our probability distributions, `l_probs` ~~and `l_cond_probs`~~, the function above will spit out the entropy of `l`'s generation N ~~and the conditional entropy of `l`'s Generation N given `l`'s Generation N+1 respectively.~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a11f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_entropy = entropy(l_probs)\n",
    "\n",
    "# l_cond_entropy = calculate_entropy(l_cond_probs)\n",
    "\n",
    "print(l_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43187a7b",
   "metadata": {},
   "source": [
    "We need a second function to calculate conditional entropy, which is slightly more complex. Here, we calculate the probability of B and A multiplied by the probability of B and A over B. We can re-use our `calculate_probs()` function to calculate to the probability of each pair (p(B and A))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(pairs,terms):\n",
    "    p_pairs = calculate_probs(pairs)\n",
    "    \n",
    "    #print('pairs: ', pairs, 'probabilities of pairs: ', p_pairs)\n",
    "        \n",
    "    p_cond = calculate_conditional_probs(pairs,terms)\n",
    "#     print('terms: ', terms, 'probabilities of terms: blank', 'conditional_probabilities: ', p_cond)\n",
    "    \n",
    "    entropy = 0\n",
    "    \n",
    "    for p in p_cond:\n",
    "        index = p_cond.index(p)\n",
    "#         entropy += p_pairs[index]*math.log2(p)\n",
    "        entropy += p_pairs[index]*math.log(p)\n",
    "        #print('p(a,b) = ', p_pairs[index], 'p(a|b) = ', p)\n",
    "            \n",
    "    return -entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fcbd6",
   "metadata": {},
   "source": [
    "These two values can then be used to calculate mutual information. Because of our 'top-down' approach, this will be equal to the entropy of `l`'s Generation N minus the conditional entropy of `l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ab6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_mi(pairs,terms1,terms2):\n",
    "#     # probs = calculate_probs(terms1)\n",
    "#     probs = calculate_probs(terms2) # for testing\n",
    "#     # print('terms: ', terms2, 'probability distribution of GN terms: ', probs)\n",
    "#     entropy = calculate_entropy(probs)\n",
    "#     # conditional_entropy = calculate_cond_entropy(pairs,terms2)\n",
    "#     conditional_entropy = calculate_cond_entropy(pairs,terms1) # for testing\n",
    "#     # print('entropy of GN1 = ', entropy, 'conditional entropy of system = ', conditional_entropy)\n",
    "#     return entropy - conditional_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(e,ce):\n",
    "    return e - ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a144f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_e = entropy(l_probs)\n",
    "l_ce = conditional_entropy(l_pairs,l_GN)\n",
    "l_mi = mutual_information(l_e,l_ce)\n",
    "\n",
    "print('mi = ', l_mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca8523",
   "metadata": {},
   "source": [
    "## Getting neat and tidy\n",
    "\n",
    "Now let's write a function that wraps up aaaaall of the above neatly. We want to return entropy, conditional entropy, and mutual information individually so we can keep track of these values for the analysis later. This will be particularly useful for the simulation work coming up next, where we may want to visualise mutual information by entropy at one generation.\n",
    "\n",
    "First though, we want to write a flag function that tells us if something's wrong with the calculations. MI cannot be less than 0, so if this happens, we want all of the relevant information to help us solve the problem to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mi_check(pairs,GN,GN1,probs):\n",
    "    #print('STOP: SOMETHING IS VERY WRONG')\n",
    "    p_pairs = calculate_probs(pairs)\n",
    "    cp = calculate_conditional_probs(pairs,GN)\n",
    "    for term,prob in zip(set(GN1),probs):\n",
    "        print('term: ', term, 'prob:', prob)\n",
    "    for pair in set(pairs):\n",
    "        index = list(set(pairs)).index(pair)\n",
    "        print('pair: ', pair, 'prob:', p_pairs[index], 'prob ' + pair[1] +'|' + pair[0], cp[index])\n",
    "#     print('probability distribution of GN1: ', set(GN1), probs)\n",
    "#     print('probability distribution of pairs: ', set(pairs), calculate_probs(pairs))\n",
    "#     print('conditional probability of pairs: ', set(pairs), calculate_conditional_probs(pairs,GN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b7ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ics(ks):\n",
    "    pairs = get_pairs(ks,kt.ics_pairs)\n",
    "    GN,GN1 = split_generations(pairs)\n",
    "    probs = calculate_probs(GN1)\n",
    "    e = entropy(probs)\n",
    "    ce = conditional_entropy(pairs,GN)\n",
    "    mi = mutual_information(e,ce)\n",
    "    for pair in set(pairs):\n",
    "        print(pair,pairs.count(pair))\n",
    "    for term in set(GN):\n",
    "        print(term,GN.count(term))\n",
    "    for term in set(GN1):\n",
    "        print(term, GN1.count(term))\n",
    "    \n",
    "    if mi < 0:\n",
    "        print('mi = ', mi, 'ce = ', ce, 'e = ', e)\n",
    "        mi_check(pairs,GN,GN1,probs)\n",
    "        \n",
    "    return mi,ce,e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66f8f2",
   "metadata": {},
   "source": [
    "To make sure that our function (with all its hand-calculated components) is working effectively, we can write a quick function that uses a pre-existing MI calculator `mutual_info_score()` from `sklearn` to double check our results. It's possible that they will yield slightly different scores (given that our function knows which terms pair together with what frequency, which `mutual_info_score()` doesn't know), but it is still a good baseline to work from. Ideally, we would like to use the hand-calculations so that we can record the entropy and conditional entropy associated with each kinship system alongside the MI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bc818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def easy_mi(ks):\n",
    "    pairs = get_pairs(ks, kt.ics_pairs)\n",
    "    GN,GN1 = split_generations(pairs)\n",
    "    #print(pairs)\n",
    "    #GN,GN1 = split_by_gen(ks)\n",
    "    # pair_codes = code_pairs(pairs)\n",
    "    if pairs: # if there are any matching pairs in this language\n",
    "        mi = mutual_info_score(GN,GN1)\n",
    "        #mi2 = mutual_info_score(GN1,GN)\n",
    "        if mi < 0:\n",
    "            print(mi)\n",
    "            print('SOMETHING IS VERY WRONG')\n",
    "            #print(GN,GN1)\n",
    "        return mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a18abb",
   "metadata": {},
   "source": [
    "## Simulating kinship systems\n",
    "\n",
    "We now have a function that can take a kinship system and output a mutual information score for the terms in Ego and Ego's parents' generations. However, while running this function on all the world's languages can tell us something about the distribution of internal co-selection across the world, it doesn't tell us whether the world's languages co-select at a greater rate than chance. If we want to argue that internal co-selection is a product of cultural evolution, we need to dispel the possibility that it occurs by chance.\n",
    "\n",
    "To get an idea of what chance is, we need to simulate some truly randomly generated systems. We can compare the MI of these simulations to the real languages to see whether the real languages have significantly greater mutual information between generations.\n",
    "\n",
    "Because MI is dependent on the amount of variation in a language, we need a simulation which maintains the number of terms while randomising which child terms pair with which parent terms. So we will take each language in our data, and randomly scramble which terms go with which types (within generation).\n",
    "\n",
    "To do this, we need:\n",
    "\n",
    "* A function to extract the kinship system of a language from kinbank (check!)\n",
    "* A function that filters the two generations we are interested in (sort of check!)\n",
    "* A function that takes all of the terms in that system and randomly reassigns them to types.\n",
    "* A function that repeats this process a bunch of times.\n",
    "\n",
    "Let's extract a random language from kinbank to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(101)\n",
    "\n",
    "file = random_language(all_kb_files)\n",
    "l = get_kin_terms(filepath + file)\n",
    "\n",
    "print(file,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197599c",
   "metadata": {},
   "source": [
    "Now we have a kinship system, we can write a function to filter out the relevant terms into two lists - one for Ego's generation and one for Ego's parents' generation. In `kintypes`, we have lists of kin types for each generation which can help us with this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_gen(ks):\n",
    "    g1 = {}\n",
    "    g2 = {}\n",
    "    for entry in ks:\n",
    "        if entry in kt.generation_n:\n",
    "            g1[entry] = ks[entry]\n",
    "        elif entry in kt.generation_n1:\n",
    "            g2[entry] = ks[entry]\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return g1,g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e12666",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1,g2 = split_by_gen(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e1ba9",
   "metadata": {},
   "source": [
    "Now we can randomly redistribute the keys in these dictionaries among the values in these dictionaries and combine them, giving us a simulated kinship system that maintains the amount of variation within generations while completely randomising the information shared between those two generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210bbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomise_generation(g):\n",
    "    sim_g = {}\n",
    "    terms = list(g.values())\n",
    "    types = list(g.keys())\n",
    "    random.shuffle(terms)\n",
    "    \n",
    "    for i in range(len(g)):\n",
    "        random_term = terms[i]\n",
    "        kintype = types[i]\n",
    "        sim_g[kintype] = random_term\n",
    "        \n",
    "    return sim_g\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g1)\n",
    "randomise_generation(g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d79e7",
   "metadata": {},
   "source": [
    "And finally a function that splits by generation, randomises the two generations, and sticks them back together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_ks(ks):\n",
    "    gN, gN1 = split_by_gen(ks)\n",
    "    gN_sim = randomise_generation(gN)\n",
    "    gN1_sim = randomise_generation(gN1)\n",
    "    \n",
    "    return {**gN_sim, **gN1_sim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f69ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sim = shuffle_ks(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce0fa4",
   "metadata": {},
   "source": [
    "Now let's check the MI of our random language `l` and compare it against our simulation of `l`, `l_sim`. We can see that their entropy is identical (as to be expected as the amount of variation is the same) but their conditional entropy varies. In this instance we get a smaller MI for the simulation than for the real language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_ics(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_ics(l_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f31948",
   "metadata": {},
   "source": [
    "Now we can create a function that takes a language, randomises it and calculates its MI a specified number of times, and saves all of those values to a dataframe to be analysed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed484ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(file,times):\n",
    "    filepath = '../languages/kinbank/'\n",
    "    language = file[:-13]\n",
    "    ks = get_kin_terms(filepath + file)\n",
    "    df = []\n",
    "    print(file)\n",
    "    for i in range(times):\n",
    "        results = {}\n",
    "        shuffled_system = shuffle_ks(ks)\n",
    "        mi = easy_mi(shuffled_system)\n",
    "#         mi,ce,e = calculate_ics(shuffled_system)\n",
    "        mi_by_hand,ce,e = calculate_ics(shuffled_system)\n",
    "        #print(mi,mi_by_hand)\n",
    "        \n",
    "        #if mi != mi_by_hand:\n",
    "            #print(shuffled_system)\n",
    "        \n",
    "        if mi:\n",
    "            results['simulation'] = str(i)\n",
    "            results['mutual_information'] = mi\n",
    "            results['by hand mutual information'] = mi_by_hand\n",
    "            #results['entropy'] = e\n",
    "            #results['conditional_entropy'] = ce\n",
    "            for i in shuffled_system:\n",
    "                results[i] = shuffled_system[i]\n",
    "\n",
    "            df.append(results)\n",
    "    \n",
    "    pd.DataFrame(df).to_csv('../data/raw/ics_' + language + '.csv',index=False)\n",
    "        \n",
    "    return pd.DataFrame(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecfed1",
   "metadata": {},
   "source": [
    "And we can test that with just a few rounds of the simulation for our random language before running the full simulation on all the kinbank files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81a013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using hand-calculated mi\n",
    "simulation(file,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_ics_simulation(all_files):\n",
    "    for file in all_files:\n",
    "        simulation(file,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600691f4",
   "metadata": {},
   "source": [
    "## Testing, testing\n",
    "\n",
    "And now to test until we brute force our way to working code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ccaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi = get_kin_terms(filepath + 'Hindi_hind1269.csv')\n",
    "hindi_pairs = get_pairs(hindi,kt.ics_pairs)\n",
    "hindiGN,hindiGN1 = split_generations(hindi_pairs)\n",
    "\n",
    "\n",
    "\n",
    "calculate_ics(hindi)\n",
    "# easy_mi(hindi)\n",
    "\n",
    "#print(hindi)\n",
    "#print(hindi_pairs)\n",
    "#print(hindiGN)\n",
    "\n",
    "conditional_entropy(hindi_pairs,hindiGN)\n",
    "\n",
    "print(calculate_ics(hindi),easy_mi(hindi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d8b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "english = get_kin_terms(filepath + 'English_stan1293.csv')\n",
    "\n",
    "print(calculate_ics(english),easy_mi(english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aguaruna = get_kin_terms(filepath + 'Aguaruna_agua1253.csv')\n",
    "\n",
    "calculate_ics(aguaruna)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c4fb2",
   "metadata": {},
   "source": [
    "### Testing hand-made languages\n",
    "\n",
    "What if our language co-selects perfectly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a7812",
   "metadata": {},
   "outputs": [],
   "source": [
    "ics_lang = {\n",
    "    'mMeB': 'aaa',\n",
    "    'mMeZ': 'bbb',\n",
    "    'mFeB': 'ccc',\n",
    "    'mFeZ': 'ddd',\n",
    "    'mMeBS': 'aaas',\n",
    "    'mMeZS': 'bbbs',\n",
    "    'mFeBS': 'cccs',\n",
    "    'mFeZS': 'ddds',\n",
    "    'mMeBD': 'aaad',\n",
    "    'mMeZD': 'bbbd',\n",
    "    'mFeBD': 'cccd',\n",
    "    'mFeZD': 'dddd',\n",
    "    'mMyB': 'eee',\n",
    "    'mMyZ': 'fff',\n",
    "    'mFyB': 'ggg',\n",
    "    'mFyZ': 'hhh',\n",
    "    'mMyBS': 'eees',\n",
    "    'mMyZS': 'fffs',\n",
    "    'mFyBS': 'gggs',\n",
    "    'mFyZS': 'hhhs',\n",
    "    'mMyBD': 'eeed',\n",
    "    'mMyZD': 'fffd',\n",
    "    'mFyBD': 'gggd',\n",
    "    'mFyZD': 'hhhd'\n",
    "}\n",
    "\n",
    "# get_pairs(ics_lang,kt.ics_pairs)\n",
    "\n",
    "calculate_ics(ics_lang)\n",
    "#easy_mi(ics_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158cc36e",
   "metadata": {},
   "source": [
    "Does that change if the son and daughter terms are the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a94461",
   "metadata": {},
   "outputs": [],
   "source": [
    "ics_lang_2 = {\n",
    "    'mMeB': 'aaa',\n",
    "    'mMeZ': 'bbb',\n",
    "    'mFeB': 'ccc',\n",
    "    'mFeZ': 'ddd',\n",
    "    'mMeBS': 'aaac',\n",
    "    'mMeZS': 'bbbc',\n",
    "    'mFeBS': 'cccc',\n",
    "    'mFeZS': 'dddc',\n",
    "    'mMeBD': 'aaac',\n",
    "    'mMeZD': 'bbbc',\n",
    "    'mFeBD': 'cccc',\n",
    "    'mFeZD': 'dddc',\n",
    "    'mMyB': 'eee',\n",
    "    'mMyZ': 'fff',\n",
    "    'mFyB': 'ggg',\n",
    "    'mFyZ': 'hhh',\n",
    "    'mMyBS': 'eeec',\n",
    "    'mMyZS': 'fffc',\n",
    "    'mFyBS': 'gggc',\n",
    "    'mFyZS': 'hhhc',\n",
    "    'mMyBD': 'eeec',\n",
    "    'mMyZD': 'fffc',\n",
    "    'mFyBD': 'gggc',\n",
    "    'mFyZD': 'hhhc'\n",
    "}\n",
    "\n",
    "calculate_ics(ics_lang_2)\n",
    "#easy_mi(ics_lang_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a8872",
   "metadata": {},
   "source": [
    "And what about a non co-selecting language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7e9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_ics_lang = {\n",
    "    'mMeB': 'aaa',\n",
    "    'mMeZ': 'bbb',\n",
    "    'mFeB': 'ddd',\n",
    "    'mFeZ': 'ddd',\n",
    "    'mMeBS': 'eed',\n",
    "    'mMeZS': 'aaas',\n",
    "    'mFeBS': 'aaas',\n",
    "    'mFeZS': 'ddds',\n",
    "    'mMeBD': 'aaad',\n",
    "    'mMeZD': 'aaad',\n",
    "    'mFeBD': 'dddd',\n",
    "    'mFeZD': 'aaad',\n",
    "    'mMyB': 'eee',\n",
    "    'mMyZ': 'fff',\n",
    "    'mFyB': 'ddd',\n",
    "    'mFyZ': 'hhh',\n",
    "    'mMyBS': 'aaas',\n",
    "    'mMyZS': 'eee',\n",
    "    'mFyBS': 'aaas',\n",
    "    'mFyZS': 'gggs',\n",
    "    'mMyBD': 'eeed',\n",
    "    'mMyZD': 'aaad',\n",
    "    'mFyBD': 'aaad',\n",
    "    'mFyZD': 'gggd'\n",
    "}\n",
    "\n",
    "calculate_ics(bad_ics_lang)\n",
    "#easy_mi(bad_ics_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb676698",
   "metadata": {},
   "source": [
    "It's not super intuitive to me that the \"worst\" languages are those with entropy 0 in one of the generations. A system like English is at least consistent - if the motivation for ICS is that it increases simplicity, then this seems entirely opposite to what we want!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72544d",
   "metadata": {},
   "source": [
    "## What about randomly generated languages?\n",
    "\n",
    "Let's write a function to randomly generate a language so we can get a feel for what good / bad mutual information scores look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a092cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_language(kin_types):\n",
    "    language = {}\n",
    "    words = []\n",
    "    letters = string.ascii_lowercase\n",
    "    \n",
    "    for i in range(len(kin_types)):\n",
    "        word = ''.join(random.choice(letters) for i in range(4))\n",
    "        words.append(word)\n",
    "        \n",
    "    print(words)\n",
    "        \n",
    "    for kt in kin_types:\n",
    "        term = random.choice(words)\n",
    "        language[kt] = term\n",
    "        \n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83016845",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate_language(ics_lang.keys())\n",
    "\n",
    "get_pairs(x,kt.ics_pairs)\n",
    "      \n",
    "calculate_ics(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23442505",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = ['mMeB','mMeZ','mFeB','mFeZ','mMeBS','mMeZS','mFeBS','mFeZS']\n",
    "\n",
    "r_l = generate_language(length)\n",
    "\n",
    "r_p = get_pairs(r_l,kt.ics_pairs)\n",
    "\n",
    "calculate_ics(r_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d12847",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ics_simulation(all_kb_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ics_simulation(all_kb_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using easy_mi() function\n",
    "\n",
    "simulation(file,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d0df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: mutual information\n",
    "print(easy_mi(l),easy_mi(l_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648247de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output: entropy, conditional entropy, mutual information\n",
    "\n",
    "print(calculate_ics(l),calculate_ics(l_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cd92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in all_kb_files:\n",
    "    print(file)\n",
    "    ks = get_kin_terms(filepath + file)\n",
    "    print(calculate_ics(ks), easy_mi(ks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agob = get_kin_terms(filepath + 'Agob-Ende-Kawam_agob1244.csv')\n",
    "print(calculate_ics(agob), easy_mi(agob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = entropy([16/46,16/46,7/46,7/46])\n",
    "\n",
    "pair_probs = [16/46,16/46,3/46,3/46,4/46,4/46]\n",
    "gn_probs = [32/46,6/46,8/46]\n",
    "\n",
    "ce = 0\n",
    "for i in range(6):\n",
    "    ce += pair_probs[i] * math.log(cond_probs[i])\n",
    "    \n",
    "e - -ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "('father', 'brother') 3\n",
    "('aunt', 'cousin') 16\n",
    "('father', 'sister') 4\n",
    "('uncle', 'cousin') 16\n",
    "('mother', 'brother') 3\n",
    "('mother', 'sister') 4\n",
    "cousin 32\n",
    "brother 6\n",
    "sister 8\n",
    "aunt 16\n",
    "uncle 16\n",
    "father 7\n",
    "mother 7\n",
    "(1.0364189954341732, 0.2712315054365003, 1.3076505008706736) 0.6145033203107284\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821a705",
   "metadata": {},
   "outputs": [],
   "source": [
    "32+6+8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
