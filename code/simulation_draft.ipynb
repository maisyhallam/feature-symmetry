{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169c3b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv # for writing dataframes to csv\n",
    "import random # for making a random choice\n",
    "import os # for scanning directories\n",
    "import itertools\n",
    "import string # for generating strings\n",
    "from collections import Counter\n",
    "\n",
    "import kintypes as kt # bringing large lists of kin types into the namespace\n",
    "import math # for calculating logs\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "testing = True # set to True to run code blocks with tests and examples\n",
    "filtering = False # set to True to run the filtering process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8983359",
   "metadata": {},
   "source": [
    "# Internal co-selection\n",
    "\n",
    "Internal co-selection refers to the tendency for kinship systems to have cross-generational consistency in the terminological distinctions or mergers that are made. That is, if your parents' elder brothers share a kin term, then so too will their children. Or if your parents' sisters are distinguished from your parents' brothers, so too will their children be distinguished. \n",
    "\n",
    "Imagine a kinship system like so: as in English, you call your parents' brothers are  *uncles*, and their sisters *aunts*. You call the child of your uncle a *chuncle*, and the child of your aunt a *chaunt*. Thus, you make the same sorts of distinctions among your parents' siblings' generation of kin as are made among your own generation of kin - and you can be certain about which children belong to which parents as a result. This is an example of internal co-selection.\n",
    "\n",
    "In this notebook, we will gather information about the robustness of this tendency cross-linguistically, using data from Kinbank, a global database of kin terminology. We will also create simulations of existing kinship systems to find out whether internal co-selection is more common in kinship systems cross-linguistically (for a given amount of terminological variation) than we would expect by chance.\n",
    "\n",
    "We will measure internal co-selection in terms of the **mutual information** between Generation N and Generation N+1 in a particular kinship system. That tells us how much information can be gained from one generation by observing the other - how certain we can be about which children 'go with' which parents. This can be calculated as the **entropy** of one generation (how much unpredictable variation there is) minus the **conditional entropy** between the two generations (how much unpredictability remains in one generation after observing another).\n",
    "\n",
    "## The procedure\n",
    "\n",
    "To calculate the mutual information (MI) of a particular kinship system, we must perform the following steps:\n",
    "\n",
    "1. Extract kin terminology data from Kinbank for this language.\n",
    "2. Condense the full kinship system down to the terms we are interested in: Ego's generation and Ego's parents' generation.\n",
    "3. Calculate the probabilities of each kin term within the generation in which it belongs; and the probabilities of each parent-child pair.\n",
    "4. Calculate entropy, conditional entropy, subtract them from each other to get the mutual information of the system.\n",
    "\n",
    "After we get that going, we can do these same calculations on simulated kinship systems.\n",
    "\n",
    "### Extract kin terminology from Kinbank\n",
    "\n",
    "First, let's actually load our data in. The following function `get_kb_files()` pulls the full list of Kinbank filenames. Later, we can iterate through these to generate MI values for every language in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd79acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kb_files(path) -> list:\n",
    "    files = []\n",
    "    directory = os.scandir(path)\n",
    "    for file in directory:\n",
    "        files.append(file.name)\n",
    "    return files\n",
    "\n",
    "all_kb_files = get_kb_files('../languages/kinbank')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc57e94",
   "metadata": {},
   "source": [
    "Using one of these filenames, we can extract the kin terminology from that file and populate a dictionary with it. We're only interested in two columns from the Kinbank data: `parameter`, which contains a short code indicating a **kin type**, and `word`, which contains the **kin term** associated with that kin type. An example of a row in the English data would be `mMeB, uncle`, where `mMeB` means 'male speaker's mother's older brother', and `uncle` is the term associated with that person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187e540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kin_terms(filepath: str) -> dict:\n",
    "    kin_system = {}\n",
    "    with open(filepath, encoding='utf8') as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        next(csv_reader) # to skip the header row\n",
    "        for line in csv_reader:\n",
    "            kin_type = line['parameter']\n",
    "            kin_term = line['word']\n",
    "            kin_system[kin_type] = kin_term\n",
    "    return kin_system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad884c7",
   "metadata": {},
   "source": [
    "Let's pick a random kinship system to test with throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63a3e70c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yidiny_yidi1250.csv {'mB': 'nganytyakuman', 'mZ': 'tyangkul', 'meB': 'yapa', 'myB': 'yapatyipa', 'mF': 'pimpi', 'mM': 'ngalpu', 'mS': 'karkun', 'mD': 'kalngkir', 'mFF': 'kamin', 'mFM': 'papim', 'mMF': 'ngatyim', 'mMM': 'kumpu', 'mSS': 'tyumpariy', 'mSD': 'tyumpariy', 'mDS': 'tyumpariy', 'mDD': 'tyumpariy', 'mFB': 'pimpi', 'mFZ': 'tyutyum', 'mMB': 'kalnga', 'mMZ': 'ngalpu', 'mBS': 'karkun', 'mBD': 'kalngkir', 'mFZD': 'manka', 'mMBD': 'manka', 'mFZS': 'manka', 'mMBS': 'manka', 'mH': 'mungka', 'mW': 'wakal', 'mZH': 'muwa', 'mWB': 'muwa', 'mWZ': 'wakal', 'mSW': 'tungkarr', 'mDH': 'tungkarr', 'meZ': 'tyangkul', 'myZ': 'tyangkul', 'mFeB': 'pimpi', 'mFyB': 'pimpi', 'mFeZ': 'tyutyum', 'mFyZ': 'tyutyum', 'mMeZ': 'ngalpu', 'mMyZ': 'ngalpu', 'mMeB': 'kalnga', 'mMyB': 'kalnga', 'meBS': 'karkun', 'myBS': 'karkun', 'meBD': 'kalngkir', 'myBD': 'kalngkir', 'mFeZS': 'manka', 'mFyZS': 'manka', 'mFeZD': 'manka', 'mFyZD': 'manka', 'mMeBS': 'manka', 'mMyBS': 'manka', 'mMeBD': 'manka', 'mMyBD': 'manka', 'mFZeS': 'manka', 'mFZyS': 'manka', 'mFZeD': 'manka', 'mFZyD': 'manka', 'mMBeS': 'manka', 'mMByS': 'manka', 'mMBeD': 'manka', 'mMByD': 'manka', 'fB': 'nganytyakuman', 'fZ': 'tyangkul', 'feB': 'yapa', 'fyB': 'yapatyipa', 'fF': 'pimpi', 'fM': 'ngalpu', 'fS': 'karkun', 'fD': 'kalngkir', 'fFF': 'kamin', 'fFM': 'papim', 'fMF': 'ngatyim', 'fMM': 'kumpu', 'fSS': 'tyumpariy', 'fSD': 'tyumpariy', 'fDS': 'tyumpariy', 'fDD': 'tyumpariy', 'fFB': 'pimpi', 'fFZ': 'tyutyum', 'fMB': 'kalnga', 'fMZ': 'ngalpu', 'fBS': 'karkun', 'fBD': 'kalngkir', 'fFZD': 'manka', 'fMBD': 'manka', 'fFZS': 'manka', 'fMBS': 'manka', 'fH': 'mungka', 'fW': 'wakal', 'fZH': 'muwa', 'fWB': 'muwa', 'fWZ': 'wakal', 'fSW': 'tungkarr', 'fDH': 'tungkarr', 'feZ': 'tyangkul', 'fyZ': 'tyangkul', 'fFeB': 'pimpi', 'fFyB': 'pimpi', 'fFeZ': 'tyutyum', 'fFyZ': 'tyutyum', 'fMeZ': 'ngalpu', 'fMyZ': 'ngalpu', 'fMeB': 'kalnga', 'fMyB': 'kalnga', 'feBS': 'karkun', 'fyBS': 'karkun', 'feBD': 'kalngkir', 'fyBD': 'kalngkir', 'fFeZS': 'manka', 'fFyZS': 'manka', 'fFeZD': 'manka', 'fFyZD': 'manka', 'fMeBS': 'manka', 'fMyBS': 'manka', 'fMeBD': 'manka', 'fMyBD': 'manka', 'fFZeS': 'manka', 'fFZyS': 'manka', 'fFZeD': 'manka', 'fFZyD': 'manka', 'fMBeS': 'manka', 'fMByS': 'manka', 'fMBeD': 'manka', 'fMByD': 'manka'}\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    \n",
    "    random.seed(47) # set a seed for reproducibility\n",
    "\n",
    "    file = random.choice(all_kb_files) # pick a random filename from all_kb_files\n",
    "\n",
    "    filepath = '../languages/kinbank/' # the filepath where the kinbank files are kept\n",
    "\n",
    "    k = get_kin_terms(filepath + file)\n",
    "\n",
    "    print(file,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ac3ae",
   "metadata": {},
   "source": [
    "As we can see from printing the system, there's a lot of extra kin terms here that we don't need for our experiment today. We're only interested in Ego and Ego's parents' generations, but the system contains kin types like `mS` (male speaker's son) or `mDD` (make speaker's daughter's daughter). In the next section, we'll reduce `k` down to just the terms we're interested in.\n",
    "\n",
    "### Condense the system down\n",
    "\n",
    "The list of possible **kin types** is far larger and more unwieldy than the set of **kin terms** in any language. For instance, while 'father's elder brother' and 'father's younger brother' are not distinguished in English (both take the term *uncle*), these distinctions are indeed encoded by terminology in other languages, like Hindi.\n",
    "\n",
    "We want create a data structure that pairs up parent types with the corresponding child types. This is because we're interested in whether kinship systems maintain patterns of terminological distinctions and mergers across these two generations, we will need to know which parent terms 'go with' which child terms.\n",
    "\n",
    "In `kintypes`, you will find **a list of pairs of kin types**, where the first element in the pair is a parent type, and the second is their child; e.g. `mMeB` and `mMeBD` (mother's elder brother and mother's elder brother's daughter). We will be filtering our full kinship system according to this list of pairs; that is, both types in the pair need to be present to be counted in the MI calculation.\n",
    "\n",
    "The following function takes a kinship system as input, and outputs a list of tuples. The first element in the tuple is the parent term, the second is the corresponding child term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "074af258-9956-433a-a588-b040e73b488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ks(ks: dict) -> dict:\n",
    "    filtered_ks = {}\n",
    "    for pair in kt.ics_pairs:\n",
    "        if pair[0] in ks and pair[1] in ks:\n",
    "            filtered_ks[pair[0]] = ks[pair[0]]\n",
    "            filtered_ks[pair[1]] = ks[pair[1]]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return filtered_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe182e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(ks: dict) -> list:\n",
    "    pairs_of_terms = []\n",
    "    parent_types = []\n",
    "\n",
    "    for pair in kt.ics_pairs:\n",
    "        if pair[0] in ks and pair[1] in ks:\n",
    "            pairs_of_terms.append((ks[pair[0]],ks[pair[1]]))\n",
    "            parent_types.append(pair[0])\n",
    "                \n",
    "    return pairs_of_terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975bb747",
   "metadata": {},
   "source": [
    "But for our calculations, we'll still need to know which terms belong to which generation. Luckily, we know that the 0th element in each tuple is from Ego's parents' generation and the 1st element is from Ego's generation. So we can happily split these tuples down the middle and populate two lists with the terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ede57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pairs(pairs: list) -> list:\n",
    "    gn = []\n",
    "    gn1 = []\n",
    "    for pair in pairs:\n",
    "        gn.append(pair[1])\n",
    "        gn1.append(pair[0])\n",
    "    \n",
    "    return gn,gn1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e1058",
   "metadata": {},
   "source": [
    "To illustrate what these functions do, let's test them out with our random kinship system, `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a91da17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ngalpu', 'yapa'), ('ngalpu', 'yapatyipa'), ('ngalpu', 'tyangkul'), ('ngalpu', 'tyangkul'), ('pimpi', 'yapa'), ('pimpi', 'yapatyipa'), ('pimpi', 'tyangkul'), ('pimpi', 'tyangkul'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('ngalpu', 'yapa'), ('ngalpu', 'yapatyipa'), ('ngalpu', 'tyangkul'), ('ngalpu', 'tyangkul'), ('pimpi', 'yapa'), ('pimpi', 'yapatyipa'), ('pimpi', 'tyangkul'), ('pimpi', 'tyangkul'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka')]\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    k_pairs = get_pairs(k)\n",
    "    print(k_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3924bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ego's generation:  ['yapa', 'yapatyipa', 'tyangkul', 'tyangkul', 'yapa', 'yapatyipa', 'tyangkul', 'tyangkul', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka', 'yapa', 'yapatyipa', 'tyangkul', 'tyangkul', 'yapa', 'yapatyipa', 'tyangkul', 'tyangkul', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka', 'manka'] \n",
      "\n",
      "Ego's parents' generation:  ['ngalpu', 'ngalpu', 'ngalpu', 'ngalpu', 'pimpi', 'pimpi', 'pimpi', 'pimpi', 'kalnga', 'kalnga', 'kalnga', 'kalnga', 'tyutyum', 'tyutyum', 'tyutyum', 'tyutyum', 'ngalpu', 'ngalpu', 'ngalpu', 'ngalpu', 'pimpi', 'pimpi', 'pimpi', 'pimpi', 'kalnga', 'kalnga', 'kalnga', 'kalnga', 'tyutyum', 'tyutyum', 'tyutyum', 'tyutyum']\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    \n",
    "    k_gn,k_gn1 = split_pairs(k_pairs)\n",
    "\n",
    "    print(\"Ego's generation: \", k_gn, '\\n')\n",
    "\n",
    "    print(\"Ego's parents' generation: \", k_gn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98db6f2",
   "metadata": {},
   "source": [
    "`get_pairs()` gives us a long list of pairs.\n",
    "\n",
    "`split_pairs()` takes this long list of pairs and sorts it into terms that belong to Ego's generation and terms that belong to Ego's parents' generation. Importantly, since the order of the `pairs` list is preserved when we run `split_generations()`, we can still work out which terms form a parent-child pair by indexing `gn` and `gn1`.\n",
    "\n",
    "Now we have our data structures, we can start to do some calculations.\n",
    "\n",
    "### Calculating probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79314427",
   "metadata": {},
   "source": [
    "To calculate entropy, we need a probability distribution over the terms in one single generation of a kinship system. So let's start with a function that can calculate the probability of a particular term.\n",
    "\n",
    "Given a term and the full list of terms in the same generation, this function counts how many times that term exists in `generation` and divides that by the total length of `generation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0bd92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(term: str, generation: list) -> float:\n",
    "    #print(generation.count(term),len(generation))\n",
    "    return generation.count(term)/len(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97324517",
   "metadata": {},
   "source": [
    "So if we pick a term at random from our Nogai kinship system, it will output the probability of picking that term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb7e5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation n+1\n",
      "tyutyum 0.25\n",
      "pimpi 0.25\n",
      "ngalpu 0.25\n",
      "kalnga 0.25\n",
      "\n",
      "Generation n\n",
      "manka 0.5\n",
      "yapatyipa 0.125\n",
      "yapa 0.125\n",
      "tyangkul 0.25\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    print('Generation n+1')\n",
    "    for term in set(k_gn1):\n",
    "        print(term, probability(term,k_gn1))\n",
    "    print('\\nGeneration n')\n",
    "    for term in set(k_gn):\n",
    "        print(term,probability(term,k_gn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63468b",
   "metadata": {},
   "source": [
    "When calculating mutual information, we also need the **conditional entropy** between the two generations of our system. To calculate this, we will need not only the probabilities of terms in a generation, but also the **joint probabilities** of every pair of terms across those two generations. In other words, we need to calculate the probabilities of our `get_pairs` output.\n",
    "\n",
    "Given two terms, this function counts how many pairs made of those two terms exist in `pairs`, then divides that by the total length of `pairs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b878e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_probability(term1: str, term2: str, pairs: list) -> float:\n",
    "    pair = (term1,term2)\n",
    "    # print(pairs.count(pair)/len(pairs))\n",
    "    return pairs.count(pair)/len(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e21575",
   "metadata": {},
   "source": [
    "Once again, we can test this with a random pair from our list of pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb88183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pimpi', 'tyangkul')\n",
      "0.125\n",
      "('pimpi', 'yapa')\n",
      "0.0625\n",
      "('kalnga', 'manka')\n",
      "0.25\n",
      "('pimpi', 'yapatyipa')\n",
      "0.0625\n",
      "('ngalpu', 'tyangkul')\n",
      "0.125\n",
      "('ngalpu', 'yapa')\n",
      "0.0625\n",
      "('tyutyum', 'manka')\n",
      "0.25\n",
      "('ngalpu', 'yapatyipa')\n",
      "0.0625\n",
      "[0.125, 0.0625, 0.25, 0.0625, 0.125, 0.0625, 0.25, 0.0625] 1.0\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    sum_jp = []\n",
    "    for pair in set(k_pairs):\n",
    "        print(pair)\n",
    "        jp = joint_probability(pair[0],pair[1],k_pairs)\n",
    "        print(jp)\n",
    "        sum_jp.append(jp)\n",
    "        # print(pair, jp)\n",
    "    print(sum_jp, sum(sum_jp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f58b79-4025-496a-9c38-164c4d1dd38a",
   "metadata": {},
   "source": [
    "Sometimes, these probability values will be really really small, but non-zero, leading to rounding errors where the probabilities do not sum to 1. To resolve this, we can normalise our probability distribution before we use it to do any further calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "252e0afe-3f5b-43b7-b185-77810300db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(probabilities):\n",
    "    \"\"\"Edited from https://stackoverflow.com/questions/26916150/normalize-small-probabilities-in-python#26916260\"\"\"\n",
    "    if sum(probabilities) > 0:\n",
    "        factor = 1 / sum(probabilities)\n",
    "        return [factor * p for p in probabilities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9868dc4-bbd1-43a2-bdd0-a03f8543ff51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pimpi', 'tyangkul')\n",
      "0.125\n",
      "('pimpi', 'yapa')\n",
      "0.0625\n",
      "('kalnga', 'manka')\n",
      "0.25\n",
      "('pimpi', 'yapatyipa')\n",
      "0.0625\n",
      "('ngalpu', 'tyangkul')\n",
      "0.125\n",
      "('ngalpu', 'yapa')\n",
      "0.0625\n",
      "('tyutyum', 'manka')\n",
      "0.25\n",
      "('ngalpu', 'yapatyipa')\n",
      "0.0625\n",
      "[0.125, 0.0625, 0.25, 0.0625, 0.125, 0.0625, 0.25, 0.0625] [0.125, 0.0625, 0.25, 0.0625, 0.125, 0.0625, 0.25, 0.0625]\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    sum_jp = []\n",
    "    for pair in set(k_pairs):\n",
    "        print(pair)\n",
    "        jp = joint_probability(pair[0],pair[1],k_pairs)\n",
    "        print(jp)\n",
    "        sum_jp.append(jp)\n",
    "    print(sum_jp, normalise(sum_jp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1da569",
   "metadata": {},
   "source": [
    "Now we can calculate probabilities, we can use these functions to calculate entropy, conditional entropy, and mutual information.\n",
    "\n",
    "### Calculating entropy and mutual information\n",
    "\n",
    "Entropy (in bits) is defined as \n",
    "\n",
    "$$\n",
    "H(X) = -\\sum_{x \\in X}p(x) log_2p(x)\n",
    "$$\n",
    "\n",
    "or, in English, it is the inverse sum over a distribution X of the probability of y * the log probability of y.\n",
    "\n",
    "Entropy is a measure of the average level of uncertainty about the possible outcomes of a variable.\n",
    "\n",
    "The functions we defined above only calculate a single probability at a time, so our next functions will need to iterate over the kinship system in order to have a full probability distribution. First, let's define a function that will iterate over a generation of the kinship system to output the entropy of that generation. \n",
    "\n",
    "Note: we only need one generation's entropy score to calculate mutual information - we will make the arbitrary choice to calculate the entropy of Ego's parents' generation later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "75d59325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entropy(generation: list) -> list:\n",
    "#     entropy = 0\n",
    "#     probs = []\n",
    "#     for term in set(generation): # using a set as we want to count each unique term only once\n",
    "#         p = probability(term,generation)\n",
    "#         probs.append(p)\n",
    "#         #print('entropy of',term,p*math.log(p))\n",
    "#     for p in normalise(probs):\n",
    "#         entropy += p*math.log2(p)\n",
    "#     return round(-entropy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae7ca6e9-2e83-4303-8677-13915f977c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(generation: list) -> list:\n",
    "    entropy = 0\n",
    "    for term in set(generation): # using a set as we want to count each unique term only once\n",
    "        p = probability(term,generation)\n",
    "        #print('entropy of',term,p*math.log(p))\n",
    "        entropy += p*math.log2(p)\n",
    "    return round(-entropy,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2b25f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    print(entropy(k_gn1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a2f49",
   "metadata": {},
   "source": [
    "Moving on, conditional entropy of Y given X is defined as\n",
    "\n",
    "$$\n",
    "H(Y|X) = -\\sum_{x \\in X,y \\in Y}p(x,y) log_2 {p(x,y) \\over p(x)}\n",
    "$$\n",
    "\n",
    "or in English, the inverse sum over two distributions Y and X of the probability of each y * the log probability of each y given x.\n",
    "\n",
    "Conditional entropy is the amount of information needed to describe the outcome of a random variable Y given that we already know the value of another random variable X.\n",
    "\n",
    "To calculate it, we need the joint probability of each pair (given by `joint_probability()`) and the probability of one member of that pair (given by `probability()`). We can then calculate the conditional probability of parent term given child term as the joint probability of those terms over the probability of the parent term.\n",
    "\n",
    "As before, we will define a function that iterates over all pairs to output the conditional entropy of Ego's generation given Ego's parents' generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "67cc6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def conditional_entropy(gn: list, pairs:list) -> float:\n",
    "#     entropy = 0\n",
    "#     jp = []\n",
    "#     pr = []\n",
    "#     probs = {}\n",
    "\n",
    "#     for term in set(gn):\n",
    "#         p = probability(term,gn)\n",
    "#         probs[term] = p\n",
    "\n",
    "#     # print(sum(probs.values()))\n",
    "#     norm_probs = normalise(probs.values())\n",
    "#     index = 0\n",
    "#     for i in probs:\n",
    "#         probs[i] = norm_probs[index]\n",
    "#         index += 1\n",
    "\n",
    "#     # print(probs)\n",
    "#     # print(sum(norm_probs))\n",
    "        \n",
    "#     for x,y in set(pairs): # x = parent, y = child\n",
    "#         # print(x,y)\n",
    "#         p_xy = joint_probability(x,y,pairs)\n",
    "#         p_y = probs[y]\n",
    "#         jp.append(p_xy)\n",
    "#         pr.append(p_y)\n",
    "        \n",
    "#     jp = normalise(jp)\n",
    "    \n",
    "#     for i in range(len(jp)):\n",
    "#         if jp[i] > 0 and pr[i] > 0:\n",
    "#             #print('p(', x, '|', y,') = ', p_xy/p_y, 'p(y) = ', p_y)\n",
    "#             entropy += jp[i] * math.log2(jp[i]/pr[i])\n",
    "#             # print(jp[i],pr[i])\n",
    "#     return round(-entropy,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b7212dc-2f71-4f9b-be80-9dcdd650e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_entropy(gn: list, pairs:list) -> float:\n",
    "    entropy = 0\n",
    "    for x,y in set(pairs): # x = parent, y = child\n",
    "        p_xy = joint_probability(x,y,pairs)\n",
    "        p_y = probability(y,gn)\n",
    "        if p_xy > 0 and p_y > 0:\n",
    "            #print('p(', x, '|', y,') = ', p_xy/p_y, 'p(y) = ', p_y)\n",
    "            entropy += p_xy * math.log2(p_xy/p_y)\n",
    "    return round(-entropy,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a664a263-1fd9-47af-82a3-7428b1044579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_entropy(k_gn,k_pairs)\n",
    "\n",
    "# sum([0.14285714285714285,0.2857142857142857,0.2857142857142857,0.2857142857142857])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "105eaf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    print(conditional_entropy(k_gn,k_pairs))\n",
    "\n",
    "# [0.125, 0.0625, 0.25, 0.0625, 0.125, 0.0625, 0.25, 0.0625]\n",
    "#manka 0.5 yapatyipa 0.125 yapa 0.125 tyangkul 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef71be",
   "metadata": {},
   "source": [
    "Finally, mutual information is defined as\n",
    "\n",
    "$$\n",
    "I(X;Y) \\equiv H(X) - H(X|Y)\n",
    "$$\n",
    "\n",
    "or in English, entropy of X minus the conditional entropy of X given Y.\n",
    "\n",
    "In this study, it is equal to the entropy of Ego's parents' generation minus the conditional entropy of Ego's parents' generation given Ego's generation. It tells us how much mutual dependence there is between these two generations; i.e. how much we can know about one by observing the other.\n",
    "\n",
    "So long as we make sure to input the right entropy and conditional entropy values, we only need a simple function for this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "52b353c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(pairs: list):\n",
    "    gn,gn1 = split_pairs(pairs)\n",
    "    e = entropy(gn1)\n",
    "    ce = conditional_entropy(gn,pairs)\n",
    "    mi = e - ce\n",
    "    return round(mi,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f82cb8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    print(mutual_information(k_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9f722",
   "metadata": {},
   "source": [
    "And there we have it! Step 4 complete. We can now take any (filtered) Kinbank file and output the mutual information between Ego's generation and Ego's parents' generation in that language.\n",
    "\n",
    "But right at the beginning of this notebook, I mentioned using **simulations** to test the robustness of our claim that languages exhibit internal co-selection in their kinship systems. These simulations give us a baseline with which to compare the MI scores of real languages. Do languages across the world have greater mutual information between two generations than we would expect by chance?\n",
    "\n",
    "## Simulations\n",
    "\n",
    "If we want to argue that internal co-selection is a product of cultural evolution, we need to dispel the possibility that it occurs by chance.\n",
    "\n",
    "To get an idea of how much information would be shared between two generations purely by chance, we need to create some randomly generated kinship systems. We can compare the MI of these simulations to the real languages to see whether the real languages have significantly greater mutual information between generations.\n",
    "\n",
    "An important aspect of MI that we have not discussed so far: it is dependent on the amount of variation within the kinship system. A system with only one unique term in each generation would have MI of 0, which seems pretty terrible! But given this very limited variation (indeed, no variation), 0 is the highest MI such a language could have. As such, we perhaps need to modify our claim that kinship systems have \"high MI\" to be more specific: kinship systems in the wild have high MI *for the amount of variation in terminology they have*.\n",
    "\n",
    "To compare real languages to simulations, we need a simulation which maintains the number of terms while randomising which child terms pair with which parent terms. To do this, we will take each language in our data, and randomly scramble which terms go with which types (within generation). This will randomise the syncretisms within the generations while maintaining the same amount of variation across the system overall.\n",
    "\n",
    "To do this, we need to take the following steps:\n",
    "\n",
    "1. Extract the kinship system of a language from kinbank (check!)\n",
    "2. Filter the two generations we are interested in (check!)\n",
    "3. Randomly reassign the kinship terms to new types.\n",
    "4. Repeat the process a bunch of times for each language.\n",
    "\n",
    "We already have the infrastructure for the first two! `get_kin_terms()`,  `get_pairs()` and `split_pairs()` will do this for us. So let's skip to 3, and write a function that randomises which terms form pairs, assuming that we have already extracted the kinship system and filtered the relevant pairs.\n",
    "\n",
    "Remember that the order of `pairs` is preserved when we run `split_pairs()`. So when we pass `gn` and `gn1` to `shuffle_pairs()`, we know that we can re-unite our pairs by using the same index. Equally, when we shuffle `gn` and `gn1` in place, we know that we can safely combine them to make a new, randomised pair in place of the 'real' Nogai pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67fcc76f-8825-40f0-82ee-d898255d5b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ks(ks):\n",
    "    filtered_ks = filter_ks(ks)\n",
    "    gn = {}\n",
    "    gn1 = {}\n",
    "    for entry in filtered_ks:\n",
    "        if entry in kt.generation_n:\n",
    "            gn[entry] = filtered_ks[entry]\n",
    "        elif entry in kt.generation_n1:\n",
    "            gn1[entry] = filtered_ks[entry]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return gn,gn1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e03b325a-48dc-4f42-b60a-8460f311e92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'meB': 'yapa', 'myB': 'yapatyipa', 'meZ': 'tyangkul', 'myZ': 'tyangkul', 'mMeBS': 'manka', 'mMeBD': 'manka', 'mMyBS': 'manka', 'mMyBD': 'manka', 'mFeZS': 'manka', 'mFeZD': 'manka', 'mFyZS': 'manka', 'mFyZD': 'manka', 'feB': 'yapa', 'fyB': 'yapatyipa', 'feZ': 'tyangkul', 'fyZ': 'tyangkul', 'fMeBS': 'manka', 'fMeBD': 'manka', 'fMyBS': 'manka', 'fMyBD': 'manka', 'fFeZS': 'manka', 'fFeZD': 'manka', 'fFyZS': 'manka', 'fFyZD': 'manka'}, {'mM': 'ngalpu', 'mF': 'pimpi', 'mMeB': 'kalnga', 'mMyB': 'kalnga', 'mFeZ': 'tyutyum', 'mFyZ': 'tyutyum', 'fM': 'ngalpu', 'fF': 'pimpi', 'fMeB': 'kalnga', 'fMyB': 'kalnga', 'fFeZ': 'tyutyum', 'fFyZ': 'tyutyum'})\n"
     ]
    }
   ],
   "source": [
    "print(split_ks(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7db23cfc-0ae5-4fdc-96db-790639f2e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_ks(ks):\n",
    "    gn_terms = []\n",
    "    gn,gn1 = split_ks(ks)\n",
    "    for term in gn:\n",
    "        gn_terms.append(gn[term])\n",
    "\n",
    "    random.shuffle(gn_terms)\n",
    "    \n",
    "    for i in range(len(gn)):\n",
    "        # print(i)\n",
    "        key = list(gn.keys())[i]\n",
    "        ks[key] = gn_terms[i]\n",
    "\n",
    "    return ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df10df4c-c76e-40d1-abc8-751d528533d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mB': 'nganytyakuman', 'mZ': 'tyangkul', 'meB': 'manka', 'myB': 'manka', 'mF': 'pimpi', 'mM': 'ngalpu', 'mS': 'karkun', 'mD': 'kalngkir', 'mFF': 'kamin', 'mFM': 'papim', 'mMF': 'ngatyim', 'mMM': 'kumpu', 'mSS': 'tyumpariy', 'mSD': 'tyumpariy', 'mDS': 'tyumpariy', 'mDD': 'tyumpariy', 'mFB': 'pimpi', 'mFZ': 'tyutyum', 'mMB': 'kalnga', 'mMZ': 'ngalpu', 'mBS': 'karkun', 'mBD': 'kalngkir', 'mFZD': 'manka', 'mMBD': 'manka', 'mFZS': 'manka', 'mMBS': 'manka', 'mH': 'mungka', 'mW': 'wakal', 'mZH': 'muwa', 'mWB': 'muwa', 'mWZ': 'wakal', 'mSW': 'tungkarr', 'mDH': 'tungkarr', 'meZ': 'manka', 'myZ': 'manka', 'mFeB': 'pimpi', 'mFyB': 'pimpi', 'mFeZ': 'tyutyum', 'mFyZ': 'tyutyum', 'mMeZ': 'ngalpu', 'mMyZ': 'ngalpu', 'mMeB': 'kalnga', 'mMyB': 'kalnga', 'meBS': 'karkun', 'myBS': 'karkun', 'meBD': 'kalngkir', 'myBD': 'kalngkir', 'mFeZS': 'yapatyipa', 'mFyZS': 'manka', 'mFeZD': 'tyangkul', 'mFyZD': 'manka', 'mMeBS': 'manka', 'mMyBS': 'manka', 'mMeBD': 'tyangkul', 'mMyBD': 'manka', 'mFZeS': 'manka', 'mFZyS': 'manka', 'mFZeD': 'manka', 'mFZyD': 'manka', 'mMBeS': 'manka', 'mMByS': 'manka', 'mMBeD': 'manka', 'mMByD': 'manka', 'fB': 'nganytyakuman', 'fZ': 'tyangkul', 'feB': 'yapa', 'fyB': 'manka', 'fF': 'pimpi', 'fM': 'ngalpu', 'fS': 'karkun', 'fD': 'kalngkir', 'fFF': 'kamin', 'fFM': 'papim', 'fMF': 'ngatyim', 'fMM': 'kumpu', 'fSS': 'tyumpariy', 'fSD': 'tyumpariy', 'fDS': 'tyumpariy', 'fDD': 'tyumpariy', 'fFB': 'pimpi', 'fFZ': 'tyutyum', 'fMB': 'kalnga', 'fMZ': 'ngalpu', 'fBS': 'karkun', 'fBD': 'kalngkir', 'fFZD': 'manka', 'fMBD': 'manka', 'fFZS': 'manka', 'fMBS': 'manka', 'fH': 'mungka', 'fW': 'wakal', 'fZH': 'muwa', 'fWB': 'muwa', 'fWZ': 'wakal', 'fSW': 'tungkarr', 'fDH': 'tungkarr', 'feZ': 'manka', 'fyZ': 'yapa', 'fFeB': 'pimpi', 'fFyB': 'pimpi', 'fFeZ': 'tyutyum', 'fFyZ': 'tyutyum', 'fMeZ': 'ngalpu', 'fMyZ': 'ngalpu', 'fMeB': 'kalnga', 'fMyB': 'kalnga', 'feBS': 'karkun', 'fyBS': 'karkun', 'feBD': 'kalngkir', 'fyBD': 'kalngkir', 'fFeZS': 'tyangkul', 'fFyZS': 'yapatyipa', 'fFeZD': 'manka', 'fFyZD': 'tyangkul', 'fMeBS': 'manka', 'fMyBS': 'manka', 'fMeBD': 'manka', 'fMyBD': 'manka', 'fFZeS': 'manka', 'fFZyS': 'manka', 'fFZeD': 'manka', 'fFZyD': 'manka', 'fMBeS': 'manka', 'fMByS': 'manka', 'fMBeD': 'manka', 'fMByD': 'manka'}\n"
     ]
    }
   ],
   "source": [
    "print(shuffle_ks(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f05b00-75fa-467d-aafa-e140a5b13654",
   "metadata": {},
   "source": [
    "This should result in a version of our kinship system `k` where all of the generation n (Ego's generation) terms should be randomly shuffled w.r.t which keys they belong with. Everything else will remain the same. The terms we don't need for our analysis will be filtered out by our `get_pairs` function at a later stage.\n",
    "\n",
    "We don't need to shuffle the generation n+1 terms - shuffling one generation is sufficient to break any correlation between them. Because each term in ego's generation pairs uniquely with a parent term (but not vice versa) this prevents a situation where new kin categories are artificially created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e43de4d1-0fc6-4363-a6f8-2779d76e7a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['manka', 'manka', 'manka', 'tyangkul', 'manka', 'manka', 'manka', 'tyangkul', 'manka', 'manka', 'manka', 'manka', 'manka', 'yapatyipa', 'yapa', 'tyangkul', 'tyangkul', 'manka', 'yapa', 'manka', 'tyangkul', 'manka', 'yapa', 'manka', 'manka', 'yapatyipa', 'manka', 'manka', 'manka', 'manka', 'tyangkul', 'manka'], ['ngalpu', 'ngalpu', 'ngalpu', 'ngalpu', 'pimpi', 'pimpi', 'pimpi', 'pimpi', 'kalnga', 'kalnga', 'kalnga', 'kalnga', 'tyutyum', 'tyutyum', 'tyutyum', 'tyutyum', 'ngalpu', 'ngalpu', 'ngalpu', 'ngalpu', 'pimpi', 'pimpi', 'pimpi', 'pimpi', 'kalnga', 'kalnga', 'kalnga', 'kalnga', 'tyutyum', 'tyutyum', 'tyutyum', 'tyutyum'])\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    # print(shuffle_ks(k))\n",
    "    #print(get_pairs(shuffle_ks(k)))\n",
    "    print(split_pairs(get_pairs(shuffle_ks(k))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef3005fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ngalpu', 'yapa'), ('ngalpu', 'manka'), ('ngalpu', 'tyangkul'), ('ngalpu', 'manka'), ('pimpi', 'yapa'), ('pimpi', 'manka'), ('pimpi', 'tyangkul'), ('pimpi', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'yapatyipa'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('ngalpu', 'manka'), ('ngalpu', 'manka'), ('ngalpu', 'manka'), ('ngalpu', 'yapa'), ('pimpi', 'manka'), ('pimpi', 'manka'), ('pimpi', 'manka'), ('pimpi', 'yapa'), ('kalnga', 'manka'), ('kalnga', 'tyangkul'), ('kalnga', 'manka'), ('kalnga', 'yapatyipa'), ('tyutyum', 'manka'), ('tyutyum', 'tyangkul'), ('tyutyum', 'manka'), ('tyutyum', 'tyangkul')]\n",
      "\n",
      "\n",
      " [('ngalpu', 'yapa'), ('ngalpu', 'yapatyipa'), ('ngalpu', 'tyangkul'), ('ngalpu', 'tyangkul'), ('pimpi', 'yapa'), ('pimpi', 'yapatyipa'), ('pimpi', 'tyangkul'), ('pimpi', 'tyangkul'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('ngalpu', 'yapa'), ('ngalpu', 'yapatyipa'), ('ngalpu', 'tyangkul'), ('ngalpu', 'tyangkul'), ('pimpi', 'yapa'), ('pimpi', 'yapatyipa'), ('pimpi', 'tyangkul'), ('pimpi', 'tyangkul'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('kalnga', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka'), ('tyutyum', 'manka')]\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    sim = shuffle_ks(k)\n",
    "    sim_pairs = get_pairs(sim)\n",
    "    sim_gn,sim_gn1 = split_pairs(sim_pairs)\n",
    "    # print(Counter(sim_gn))\n",
    "    print(sim_pairs)\n",
    "    print('\\n\\n', k_pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b6ea6",
   "metadata": {},
   "source": [
    "Now we can treat `sim_pairs` just as we treated `pairs`! Let's calculate the entropy, conditional entropy, and mutual information of this simulated system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ffc70307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation:  2.0 1.8732093304262503 0.12679066957374974\n",
      "Real:  2.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    sim = shuffle_ks(k)\n",
    "    sim_pairs = get_pairs(sim)\n",
    "    sim_gn,sim_gn1 = split_pairs(sim_pairs)\n",
    "    e = entropy(sim_gn1)\n",
    "    ce = conditional_entropy(sim_gn,sim_pairs)\n",
    "    mi = mutual_information(sim_pairs)\n",
    "    print('Simulation: ', e,ce,mi)\n",
    "    print('Real: ', entropy(k_gn1),conditional_entropy(k_gn,k_pairs),mutual_information(k_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae6cfd",
   "metadata": {},
   "source": [
    "Wait! One of these values are exactly the same as the real kinship system! I thought this was a randomised simulation - what gives? \n",
    "\n",
    "Variation gives! Entropy remains the same regardless, because the amount of variation in the simulation **does not change** by design.\n",
    "\n",
    "The MI of these two systems (and by extension, the conditional entropy) **does** vary, which is what we want. Let's try with another language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7dd8479b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('pap', 'hinne'), ('metuo', 'avukokon'), ('metuo', 'mase'), ('tame', 'hinne'), ('nine', 'tu'), ('nine', 'hinne'), ('tine', 'avukokon'), ('tine', 'mase'), ('pap', 'tu'), ('tame', 'tu')}\n",
      "Counter({'hinne': 16, 'tu': 14, 'mase': 8, 'avukokon': 8})\n",
      "pap hinne\n",
      "metuo avukokon\n",
      "metuo mase\n",
      "tame hinne\n",
      "nine tu\n",
      "nine hinne\n",
      "tine avukokon\n",
      "tine mase\n",
      "pap tu\n",
      "tame tu\n",
      "pap hinne\n",
      "metuo avukokon\n",
      "metuo mase\n",
      "tame hinne\n",
      "nine tu\n",
      "nine hinne\n",
      "tine avukokon\n",
      "tine mase\n",
      "pap tu\n",
      "tame tu\n",
      "Counter({'tu': 14, 'hinne': 13, 'avukokon': 10, 'mase': 9})\n",
      "pap mase\n",
      "tine mase\n",
      "pap hinne\n",
      "metuo mase\n",
      "tine hinne\n",
      "pap avukokon\n",
      "metuo hinne\n",
      "tine avukokon\n",
      "tame mase\n",
      "pap tu\n",
      "metuo avukokon\n",
      "tine tu\n",
      "metuo tu\n",
      "nine mase\n",
      "tame hinne\n",
      "nine hinne\n",
      "tame avukokon\n",
      "tame tu\n",
      "nine avukokon\n",
      "nine tu\n",
      "pap mase\n",
      "tine mase\n",
      "pap hinne\n",
      "metuo mase\n",
      "tine hinne\n",
      "pap avukokon\n",
      "metuo hinne\n",
      "tine avukokon\n",
      "tame mase\n",
      "pap tu\n",
      "metuo avukokon\n",
      "tine tu\n",
      "metuo tu\n",
      "nine mase\n",
      "tame hinne\n",
      "nine hinne\n",
      "tame avukokon\n",
      "tame tu\n",
      "nine avukokon\n",
      "nine tu\n",
      "Real: 2.2571523171759043 1.3238390641791251 0.9333132529967791\n",
      "Simulation: 2.2571523171759043 2.1604968194712555 0.09665549770464876\n",
      "140 46\n"
     ]
    }
   ],
   "source": [
    "if testing:\n",
    "    # file2 = random.choice(all_kb_files)\n",
    "    # print(file2)\n",
    "    # k2 = get_kin_terms(filepath + 'Shoshoni_shos1248.csv')\n",
    "    k2 = get_kin_terms(filepath + 'Southeast_Ambrym_sout2859.csv')\n",
    "    # k2 = get_kin_terms(filepath + file2)\n",
    "    # print(k2)\n",
    "\n",
    "    k2_pairs = get_pairs(k2)\n",
    "    print(set(k2_pairs))\n",
    "    k2_gn,k2_gn1 = split_pairs(k2_pairs)\n",
    "    print(Counter(k2_gn))\n",
    "    k2_e = entropy(k2_gn1)\n",
    "    k2_ce = conditional_entropy(k2_gn,k2_pairs)\n",
    "    k2_mi = mutual_information(k2_pairs)\n",
    "    \n",
    "    k2_sim = shuffle_ks(k2)\n",
    "    k2_sim_pairs = get_pairs(k2_sim)\n",
    "    k2_sim_gn,k2_sim_gn1 = split_pairs(k2_sim_pairs)\n",
    "    # print(k2_sim_gn)\n",
    "    print(Counter(k2_sim_gn))\n",
    "    k2_sim_e = entropy(k2_sim_gn1)\n",
    "    k2_sim_ce = conditional_entropy(k2_sim_gn,k2_sim_pairs)\n",
    "    k2_sim_mi = mutual_information(k2_sim_pairs)\n",
    "    \n",
    "    print('Real:', k2_e,k2_ce,k2_mi)\n",
    "    print('Simulation:',k2_sim_e,k2_sim_ce,k2_sim_mi)\n",
    "    \n",
    "    print(len(k2_sim),len(k2_pairs))\n",
    "    \n",
    "    # for i in k2_pairs:\n",
    "    #     if i not in k2_sim:\n",
    "    #         print(i)\n",
    "            \n",
    "    # for i in k2_sim:\n",
    "    #     if i not in k2_pairs:\n",
    "    #         print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be79186d",
   "metadata": {},
   "source": [
    "Now we see that while the entropy of our new language and its simulation are equal, the conditional entropy for the simulation is greater and therefore the mutual information of the simulation is lower. What about if we did this 1000 times? How often would the mutual information of the simulation be lower then?\n",
    "\n",
    "## Tidying up\n",
    "\n",
    "We have all the pieces we need now to calculate MI and simulate kinship systems - all we need to do is write a few more functions that stick all of those pieces together in a neat parcel.\n",
    "\n",
    "First, a function that takes pairs and spits out entropy, conditional entropy, and MI:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef1a0e",
   "metadata": {},
   "source": [
    "Second, a function that builds a simulated list of pairs when we pass in a kinship system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efa525cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_ks(ks: dict) -> list:\n",
    "#     pairs = get_pairs(ks)\n",
    "#     if pairs:\n",
    "#         gn,gn1 = split_pairs(pairs)\n",
    "#         simulation = shuffle_pairs(gn,gn1)\n",
    "#         return simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "df837b1a-8e23-403c-99d7-bd3e245eac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ks(ks: dict) -> list:\n",
    "    simulation = shuffle_ks(ks)\n",
    "    shuffled_pairs = get_pairs(simulation)\n",
    "    return shuffled_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fe35dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(pairs,results):\n",
    "    gn,gn1 = split_pairs(pairs)\n",
    "    egn = entropy(gn)\n",
    "    egn1 = entropy(gn1)\n",
    "    ce = conditional_entropy(gn,pairs)\n",
    "    mi = mutual_information(pairs)\n",
    "    \n",
    "    results['mutual_information'] = mi\n",
    "    results['entropy_gn'] = egn\n",
    "    results['entropy_gn1'] = egn1\n",
    "    results['conditional_entropy'] = ce\n",
    "    results['variation_gn'] = len(set(gn))\n",
    "    results['variation_gn1'] = len(set(gn1))\n",
    "    results['number_of_pairs'] = len(set(pairs))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3deafb",
   "metadata": {},
   "source": [
    "And a couple of functions that put everything together, saves the results to a separate file, and output a `pandas` dataframe so that we can take a good look. `ics_simulation` takes the full list of Kinbank filenames, extracts the relevant kin terms, performs the randomisation simulation on it a specified number of times, calculates entropy, conditional entropy, and MI for each simulation, and saves all that data to a separate file. It also performs some regex magic on the filename so that we get each language's unique code as well as each language's name in full."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9064c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ics_simulation(families: list, filepath: str, filename: str, times: int):\n",
    "    df = []\n",
    "    codes = []\n",
    "    \n",
    "    for family in families:\n",
    "        all_files = get_kb_files(filepath + family)\n",
    "    \n",
    "        for file in all_files:\n",
    "            match = re.search('[a-z]{4}[0-9]{4}[a-z]?', file)\n",
    "            code = match.group()\n",
    "            language = file.split('_' + code)[0]\n",
    "\n",
    "            if code not in codes:\n",
    "                codes.append(code)\n",
    "\n",
    "                ks = get_kin_terms(filepath + family + '/' + file)\n",
    "\n",
    "                for i in range(times):\n",
    "                    pairs = simulate_ks(ks)\n",
    "                    if pairs:\n",
    "                        results = {}\n",
    "                        results['language'] = language\n",
    "                        results['language_family'] = family\n",
    "                        results['code'] = code\n",
    "                        results['simulation_code'] = code + '_' + str(i)\n",
    "                        results['simulation'] = 'Y'\n",
    "                        write_data(pairs,results)\n",
    "\n",
    "                        df.append(results)\n",
    "    \n",
    "    pd.DataFrame(df).to_csv('../data/raw/' + filename + '.csv',index=False)\n",
    "    \n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95579fa",
   "metadata": {},
   "source": [
    "`ics_real` performs similarly to `ics_simulation`, but instead of performing the randomisation, it calculates entropy, conditional entropy, and MI for the language as-is. It does this for every file in the Kinbank data and saves the data to a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "924ce47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ics_real(families: list,filepath: str,filename: str):\n",
    "    df = []\n",
    "    codes = []\n",
    "    \n",
    "    for family in families:\n",
    "        all_files = get_kb_files(filepath +  family)\n",
    "        \n",
    "        for file in all_files:\n",
    "            print(file)\n",
    "            match = re.search(\"[a-z]{4}[0-9]{4}[a-z]?\", file)\n",
    "            code = match.group()\n",
    "            language = file.split('_' + code)[0]\n",
    "\n",
    "            if code not in codes:\n",
    "                codes.append(code)\n",
    "\n",
    "                ks = get_kin_terms(filepath + family + '/' + file)\n",
    "\n",
    "                pairs = get_pairs(ks)\n",
    "\n",
    "                if pairs: # if pairs is not empty\n",
    "                    mi = mutual_information(pairs)\n",
    "\n",
    "                    results = {}\n",
    "                    results['language'] = language\n",
    "                    results['language_family'] = family\n",
    "                    results['code'] = code\n",
    "                    results['simulation_code'] = code + '_REAL'\n",
    "                    results['simulation'] = 'N'\n",
    "                    write_data(pairs,results)\n",
    "\n",
    "                    df.append(results)\n",
    "        \n",
    "    pd.DataFrame(df).to_csv('../data/raw/' + filename + '.csv',index=False)\n",
    "    \n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91e834",
   "metadata": {},
   "source": [
    "## Let's go!\n",
    "\n",
    "If we want to create a dataset from the full set of filtered language data, we just have to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c56d5dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "families = ['Austronesian','Cariban','Dravidian','Indo-European','Nakh-Daghestanian','Nuclear Trans New Guinea',\n",
    "            'Other','Pama-Nyungan','Pano-Tacanan','Salishan','Sino-Tibetan','Tai-Kadai','Tupian',\n",
    "            'Turkic','Uralic','Uto-Aztecan']\n",
    "\n",
    "language_filepath = '../languages/kinbank-family/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "affc9ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa_saaa1241.csv\n",
      "Namakura_nama1268b.csv\n",
      "Woleaian_wole1240.csv\n",
      "Nengone_neng1238.csv\n",
      "Ontong_Java_onto1237.csv\n",
      "Pama_(Paamanese)_paam1238.csv\n",
      "Sa_a_saaa1240.csv\n",
      "Tigak_tiga1245.csv\n",
      "Southwest_Tanna_sout2869.csv\n",
      "Maranao_(Lanao_Moro)_mara1404.csv\n",
      "Wiwirano_wiwi1237.csv\n",
      "Maguindanao_(Magindonao_Moro)_magu1243.csv\n",
      "Penrhyn_(Tongareva)_penr1237.csv\n",
      "Sungwaloge_(Nalemba_Edward)_mari1426g.csv\n",
      "Tolaki_tola1247.csv\n",
      "Yabem_yabe1254.csv\n",
      "Yami_Tao__yami1254.csv\n",
      "Merlav_merl1237.csv\n",
      "Maori_maor1246.csv\n",
      "West_Coast_Bajau_west2560.csv\n",
      "Sungwaloge_(Nalemba_Simeone_Tari)_mari1426f.csv\n",
      "Tausug_(Sulu_Moro)_taus1251.csv\n",
      "Tasiko_tasi1237.csv\n",
      "Mussau-Emira_muss1246.csv\n",
      "Pampanga_(Kampampangan)_pamp1243.csv\n",
      "Sungagage_mari1426i.csv\n",
      "Rade_(Rhade)_rade1240.csv\n",
      "Maori_maor1246.csv\n",
      "Mekeo_meke1243.csv\n",
      "Tialo_(Tomini)_tomi1243.csv\n",
      "Morgan1871_Kings_Mill_Islands_gilb1244.csv\n",
      "Satawalese_sata1237.csv\n",
      "Senbarei_unua1237.csv\n",
      "Mekeo_(West)_meke1243b.csv\n",
      "Takuu_taku1257.csv\n",
      "Tombulu_tomb1243.csv\n",
      "Rotumans_rotu1241.csv\n",
      "Minangkabau_mina1268.csv\n",
      "Mekongga_meko1237.csv\n",
      "Sungwaloge_(Tawet)_mari1426c.csv\n",
      "Rejang_(Rejangese)_reja1240.csv\n",
      "Xalangi_(Maevo_Vanuatu)_mari1426h.csv\n",
      "Ratagnon_rata1245.csv\n",
      "Tikopia_tiko1237.csv\n",
      "Pohnpeian_pohn1238a.csv\n",
      "Pohnpeian_pohn1238.csv\n",
      "Palauan_pala1344.csv\n",
      "Malua_Bay_malu1245.csv\n",
      "Nehan_neha1247.csv\n",
      "Nalik_(Madina)_nali1244b.csv\n",
      "Paluai_balu1257.csv\n",
      "Mele-Fila_(Ifira-Mele)_mele1250.csv\n",
      "Tokelau_toke1240a.csv\n",
      "Sika_sika1262.csv\n",
      "Samoan_samo1305a.csv\n",
      "Taumako_taum1237.csv\n",
      "Raroians_tuam1242.csv\n",
      "Wogeo_woge1237.csv\n",
      "Muna_muna1247.csv\n",
      "Rarotongan_(Cook_Islands_Maori)_raro1241.csv\n",
      "Niue_niue1239.csv\n",
      "Nakanai_naka1262.csv\n",
      "Owa_(Santa_Ana)_owaa1237.csv\n",
      "South_Marquesan_sout2866.csv\n",
      "Nage_nage1237.csv\n",
      "Moronene_moro1287.csv\n",
      "Uripiv-Wala-Rano-Atchin_urip1239.csv\n",
      "Sula_Mangoli_mang1408.csv\n",
      "Sungwadia_mari1426a.csv\n",
      "Toqabaqita_toab1237.csv\n",
      "South_Tuvaluan_(Vaitupu)_sout2865.csv\n",
      "Matukar_matu1261.csv\n",
      "Niueans_niue1239.csv\n",
      "Southeast_Ambrym_sout2859.csv\n",
      "Yakan_yaka1277.csv\n",
      "Namakura_nama1268.csv\n",
      "Muduapa_(Vitu)_mudu1242.csv\n",
      "Paici_paic1239.csv\n",
      "Waropen_waro1242.csv\n",
      "Sula_Fagudu_sula1245.csv\n",
      "Puluwatese_(Puluwat)_pulu1242.csv\n",
      "Mekeo_(North-West)_meke1243a.csv\n",
      "Morgan1871_Hawaiian_hawa1245.csv\n",
      "Sunwadia_mari1426.csv\n",
      "Torete_tore1237.csv\n",
      "Waru_waru1266.csv\n",
      "Nafsan_sout2856.csv\n",
      "Nguna_ngun1274.csv\n",
      "Waia_waia1242.csv\n",
      "Paiwan_paiw1248.csv\n",
      "Miningir_(Lunga)_mini1251.csv\n",
      "Roviana_rovi1238.csv\n",
      "Wolio_woli1241.csv\n",
      "Sundanese_sund1252.csv\n",
      "Tuvalu_(Nanumea)_tuva1244.csv\n",
      "Motu_motu1246.csv\n",
      "Wawonii_wawo1239.csv\n",
      "Proto-Oceanic_ocea1241.csv\n",
      "Niuafo'ou_niua1240.csv\n",
      "Whitesands_whit1269.csv\n",
      "Puyuma_puyu1239.csv\n",
      "Morgan1871_Kusaien_kosr1238.csv\n",
      "Rakahanga-Manihiki_raka1237.csv\n",
      "Wallisian_(East_Uvea)_wall1257.csv\n",
      "Tikopia_tiko1237a.csv\n",
      "Tamambo_malo1243.csv\n",
      "South_Efate_sout2856a.csv\n",
      "Neve'ei_vinm1237a.csv\n",
      "North_Efate_(Nguna,_Nakanamanga)_nort2836.csv\n",
      "Mota_mota1237.csv\n",
      "Old_Javanese_(Kawi)_kawi1241.csv\n",
      "Rahambuu_raha1237.csv\n",
      "Tadyawan_tady1237.csv\n",
      "Umiray_Dumaget_Agta_umir1236.csv\n",
      "Tanala_tana1285.csv\n",
      "Nanggu_nang1262.csv\n",
      "Vao_vaoo1237.csv\n",
      "Nese_nese1235.csv\n",
      "Rotinese_Termanu__term1237.csv\n",
      "Routa_rout1237.csv\n",
      "Vures_vure1239.csv\n",
      "Western_Tawbuid_(Batangan)_west2559.csv\n",
      "Tokelau_toke1240.csv\n",
      "Thao_thao1240.csv\n",
      "Pukapuka_puka1242.csv\n",
      "Watut_watu1246.csv\n",
      "Patani_pata1260.csv\n",
      "Munggava_(Rennell)_mung1271.csv\n",
      "Tongan_tong1325.csv\n",
      "Mori_Bawah_mori1268.csv\n",
      "Tiri-Mea_(Grand_Couli)_tiri1258.csv\n",
      "Manam_mana1295.csv\n",
      "Wuvulu_Aua_wuvu1239.csv\n",
      "Saaroa_saar1237.csv\n",
      "Mortlockese_mort1237.csv\n",
      "Nahavaq_sout2857.csv\n",
      "Sungwadaga_mari1426b.csv\n",
      "Maskelynes_mask1242.csv\n",
      "Mangaia_mang1402.csv\n",
      "Urak_Lawoi_urak1238.csv\n",
      "Yamdena_yamd1240.csv\n",
      "Sonsorol_sons1242.csv\n",
      "Talibabu_tali1262.csv\n",
      "Mwotlap_motl1237.csv\n",
      "Tulambatu_tula1253.csv\n",
      "Western_Bukidnon_Manobo_west2555.csv\n",
      "Tajio_taji1246.csv\n",
      "Tausug_taus1251a.csv\n",
      "Rangiora_(NW_Tuamotus)_tuam1242.csv\n",
      "Tomadino_toma1248.csv\n",
      "Old_Rapa_(Rapa)_rapa1245.csv\n",
      "Tongarevans_penr1237.csv\n",
      "Raga_(Hano_Thomas_Ennever)_hano1246b.csv\n",
      "Tangoa_(Movono)_tang1347.csv\n",
      "Raga_(Hano)_hano1246.csv\n",
      "Mangei_(Sobjo)_mang1407.csv\n",
      "North_Tanna_nort2847.csv\n",
      "Naman_litz1237.csv\n",
      "Ura_urav1235.csv\n",
      "Maragus_(Tape)_mara1399.csv\n",
      "Weda_weda1240.csv\n",
      "Zabana_(Kia)_zaba1237.csv\n",
      "Nalik_(Lukuramau)_nali1244.csv\n",
      "Riuk_Bekati'_(Dayak)_beka1241.csv\n",
      "Tokotu'a_(Kabaena)_kaba1285.csv\n",
      "Sarangani_Blaan_sara1326.csv\n",
      "Seke_(Ske)_seke1241.csv\n",
      "Vaekau-Taumako_pile1238.csv\n",
      "Tonga_(Tonga_Islands)_tong1325.csv\n",
      "Tagalog_taga1270.csv\n",
      "Merei_mere1242.csv\n",
      "Tukang_Besi_South_tuka1249.csv\n",
      "Sungwaloge_(Tauta)_mari1426e.csv\n",
      "Sie_(Sye)_siee1239.csv\n",
      "Mono-Alu_mono1273.csv\n",
      "Tubuai_tubu1240.csv\n",
      "Sikaiana_sika1261.csv\n",
      "Ulawa_ulaw1237.csv\n",
      "Rennell_Islanders_renn1242.csv\n",
      "Tirax_(Mae)_maee1241.csv\n",
      "Tungag_tung1290.csv\n",
      "Port_Sandwich_port1285.csv\n",
      "Neve'ei_vinm1237.csv\n",
      "Vera'a_vera1241.csv\n",
      "Mekeo_(East)_meke1243d.csv\n",
      "Mori_Atas_mori1269.csv\n",
      "Mangarevans_mang1401.csv\n",
      "Manggarai_mang1405.csv\n",
      "Tanampedagi_Taje_taje1237b.csv\n",
      "Mungiki_(Bellona)_mung1270.csv\n",
      "Marshallese_mars1254.csv\n",
      "Totoli_toto1304.csv\n",
      "Tahitians_tahi1242.csv\n",
      "Pangasinan_pang1290.csv\n",
      "Unua_unua1237.csv\n",
      "Sawai_sawa1247.csv\n",
      "Samoan_samo1305.csv\n",
      "Uma_Juman_(Kayan)_umaj1240.csv\n",
      "North_Marquesan_nort2845.csv\n",
      "Rapanui_(Easter_Island)_rapa1244.csv\n",
      "Pendau_pend1242.csv\n",
      "Numbami_numb1247.csv\n",
      "Olal_olal1237.csv\n",
      "Rotuman_rotu1241.csv\n",
      "Padoe_pado1242.csv\n",
      "Varisi_vari1239.csv\n",
      "Menui_menu1237.csv\n",
      "Mouk_mouk1240.csv\n",
      "Tonsea_tons1240.csv\n",
      "Mekeo_(North)_meke1243c.csv\n",
      "Tahitian_tahi1242.csv\n",
      "Tiale_tial1239.csv\n",
      "Tetum_(Tetun)_tetu1245.csv\n",
      "Mangareva_mang1401.csv\n",
      "Morgan1871_Maori_maor1246.csv\n",
      "Petapa_Taje_taje1237a.csv\n",
      "Talise_(Tolo)_tali1259.csv\n",
      "Xaracuu_(Canala)_xara1244.csv\n",
      "Sungwaloge_(Navenvene)_mari1426d.csv\n",
      "Tetun_Dili_(Tetum)_tetu1246.csv\n",
      "Marquesas_marq1246.csv\n",
      "Southeast_Babar_sout2883.csv\n",
      "Neverver_ling1265.csv\n",
      "West_Futuna_west2515.csv\n",
      "North_Ambrym_nort2839.csv\n",
      "Takia_taki1248.csv\n",
      "Macushi_macu1259.csv\n",
      "Galibi_Carib_gali1262.csv\n",
      "Waimiri_Atroari_waim1253.csv\n",
      "De_kwana_Maquiritari__maqu1238.csv\n",
      "Panare_enap1235.csv\n",
      "Wai_Wai_waiw1244.csv\n",
      "Pemon_pemo1248.csv\n",
      "Morgan1871_Tamil_tami1289.csv\n",
      "Kodava_koda1255.csv\n",
      "Malayalam_mala1464.csv\n",
      "Gondi_gond1265.csv\n",
      "Chenchu_chen1255.csv\n",
      "Kuvi_kuvi1243.csv\n",
      "Yerukula_yeru1240.csv\n",
      "Malapandaram_mala1468.csv\n",
      "Kui_kuii1252.csv\n",
      "Telugu_telu1262.csv\n",
      "Kadar_kada1242.csv\n",
      "Morgan1871_Telugu_telu1262.csv\n",
      "Morgan1871_Canarese_nucl1305.csv\n",
      "Koya_koya1251.csv\n",
      "Paliyan_pali1274.csv\n",
      "Kurukh_kuru1302.csv\n",
      "Toda_toda1252.csv\n",
      "Tamil_tami1289.csv\n",
      "Northern_Gondi_nort2702.csv\n",
      "Dandami_Maria_dand1238.csv\n",
      "Kashmiri_kash1277.csv\n",
      "Tok_Pisin_tokp1240.csv\n",
      "Modern_Welsh_wels1247.csv\n",
      "Morgan1871_Hindi_hind1269.csv\n",
      "Slovakian_slov1269.csv\n",
      "Polish_poli1260.csv\n",
      "Belarusian_bela1254.csv\n",
      "Negerhollands_nege1244.csv\n",
      "Old_Russian_oldr1238.csv\n",
      "Old_Church_Slavonic_chur1257.csv\n",
      "Serbocroation_sout1528.csv\n",
      "Middle_High_German_midd1343.csv\n",
      "Standard_Spanish_stan1288.csv\n",
      "Macedonian_mace1250.csv\n",
      "Sardinian_sard1257.csv\n",
      "Frisian_fris1239.csv\n",
      "English_stan1293.csv\n",
      "Serbs_serb1264.csv\n",
      "Old_High_German_ca_750_1050__oldh1241.csv\n",
      "Eastern_Pahari_Nepali__east1436.csv\n",
      "Albanian_Tosk__tosk1239.csv\n",
      "Sanskrit_sans1269.csv\n",
      "Morgan1871_Bengali_beng1280.csv\n",
      "Standard_Catalan_stan1289.csv\n",
      "Tajik_taji1245.csv\n",
      "Nepali_nepa1254.csv\n",
      "Bengali_beng1280.csv\n",
      "Swedish_swed1254.csv\n",
      "Urdu_urdu1245.csv\n",
      "Standard_German_stan1295.csv\n",
      "Irish_iris1253.csv\n",
      "Ossetian_osse1243.csv\n",
      "Latin_lati1261a.csv\n",
      "Panjabi_panj1256.csv\n",
      "Ancient_Greek_anci1242.csv\n",
      "Western_Armenian_homs1234.csv\n",
      "Latvian_latv1249.csv\n",
      "Czech_czec1258.csv\n",
      "Balochi_balo1260.csv\n",
      "Marathi_mara1378.csv\n",
      "Marwari_India__marw1260.csv\n",
      "Eastern_Armenian_east2283.csv\n",
      "Chavacano_chav1241.csv\n",
      "Old_Norse_oldn1244.csv\n",
      "Icelandic_icel1247.csv\n",
      "Western_Farsi_west2369.csv\n",
      "Tokharian_B_tokh1243.csv\n",
      "Standard_English_stan1293.csv\n",
      "Assamese_assa1263.csv\n",
      "Portuguese_port1283.csv\n",
      "Kriol_Roper_River_krio1252.csv\n",
      "Maithili_mait1250.csv\n",
      "Hittite_hitt1242.csv\n",
      "Luxembourgish_luxe1241.csv\n",
      "German_stan1295.csv\n",
      "Bihari_biha1245.csv\n",
      "Eastern_Yiddish_east2295.csv\n",
      "Judeo_Tat_jude1256.csv\n",
      "Albanian_alba1267.csv\n",
      "Morgan1871_Gujarati_guja1252.csv\n",
      "Old_English_ca_450_1100__olde1238.csv\n",
      "Middle_English_midd1317.csv\n",
      "Mahasu_Pahari_maha1287.csv\n",
      "Kristang_(Malacca_Creole_Portugese)_mala1533.csv\n",
      "Ossetic_osse1245.csv\n",
      "Jamaican_Creole_jama1262.csv\n",
      "Saterfriesisch_sate1242.csv\n",
      "Cornish_corn1251.csv\n",
      "Pashto_pash1269.csv\n",
      "Italian_ital1282.csv\n",
      "Oriya_oriy1255.csv\n",
      "Sindhi_sind1272.csv\n",
      "Breton_bret1244.csv\n",
      "Old_Irish_oldi1245.csv\n",
      "Central_Kurdish_cent1972.csv\n",
      "Tokharian_A_tokh1242.csv\n",
      "Old_Welsh_oldw1239.csv\n",
      "Russian_russ1263.csv\n",
      "Old_Prussian_prus1238.csv\n",
      "Wallon_wall1255.csv\n",
      "Kumaoni_kuma1273.csv\n",
      "Russian_russ1263a.csv\n",
      "Dutch_dutc1256.csv\n",
      "Lahnda_lahn1241.csv\n",
      "Latin_lati1261.csv\n",
      "Dari_dari1249.csv\n",
      "Lithuanian_lith1251.csv\n",
      "Northern_Kurdish_nort2641.csv\n",
      "Boers_afri1274.csv\n",
      "Slovenian_slov1268.csv\n",
      "Gothic_goth1244.csv\n",
      "Modern_Greek_mode1248.csv\n",
      "Morgan1871_Marathi_mara1378.csv\n",
      "Vlax_Romani_vlax1238.csv\n",
      "Bulgarian_bulg1262.csv\n",
      "Sinhala_sinh1246.csv\n",
      "Danish_dani1285.csv\n",
      "Hindi_hind1269.csv\n",
      "Ukrainian_ukra1253.csv\n",
      "Gujarati_guja1252.csv\n",
      "Western_Panjabi_west2386.csv\n",
      "Romanian_roma1327.csv\n",
      "Armenian_nucl1235.csv\n",
      "Standard_French_stan1290.csv\n",
      "Torres_Strait_Creole_(Broken)_torr1261.csv\n",
      "Norwegian_Bokmal_norw1259.csv\n",
      "Avestan_aves1237.csv\n",
      "Godoberi_ghod1238.csv\n",
      "Hinuq_hinu1240.csv\n",
      "Archi_arch1244.csv\n",
      "Aghul_aghu1253.csv\n",
      "Dargwa_Chirag__chir1284.csv\n",
      "Bats_Tsova_Tush__bats1242.csv\n",
      "Avar_avar1256.csv\n",
      "Avaz_Khunzakh__kunz1243.csv\n",
      "Dargwa_Itsari__itsa1239.csv\n",
      "Chamalal_Gigatli__giga1238.csv\n",
      "Avar_Batlux__batl1238.csv\n",
      "Bahvalal_bagv1239.csv\n",
      "Akhvakh_Northern_Akhvakh__akhv1239.csv\n",
      "Avar_Andalal__anda1281.csv\n",
      "Inxokvari_inxo1238.csv\n",
      "Chamalal_cham1309.csv\n",
      "Rutul_shin1265.csv\n",
      "Hunzib_hunz1247.csv\n",
      "Ingush_ingu1240.csv\n",
      "Budukh_budu1248.csv\n",
      "Bezhta_bezh1248.csv\n",
      "Avar_Hid_dialect__hidd1238.csv\n",
      "Avar_Ancux__ancu1238.csv\n",
      "Andi_andi1255.csv\n",
      "East_Kewa_east2516.csv\n",
      "Proto_Sogeram_soge1235.csv\n",
      "Komba_komb1273.csv\n",
      "Kalam_kala1397.csv\n",
      "Kyaka_kyak1244.csv\n",
      "Erave_(South_Kewa)_erav1244.csv\n",
      "West_Kewa_west2599.csv\n",
      "Ku_Waru_boun1245.csv\n",
      "Tlingit_tlin1245.csv\n",
      "Kimaama_kima1246.csv\n",
      "Moseten_Chimane_mose1249.csv\n",
      "Morgan1871_Hare_Indians_or_Ta-na'-tin-ne_hare1243.csv\n",
      "Morgan1871_Japanese_japa1256.csv\n",
      "Kuot_kuot1243.csv\n",
      "Buin_buin1247.csv\n",
      "Nunamiut_nort2944.csv\n",
      "Angaite_anga1316.csv\n",
      "Kemtuik_kemt1242.csv\n",
      "Mblafe_mbla1238.csv\n",
      "Mairasi_nucl1594.csv\n",
      "Nimboran_nucl1633.csv\n",
      "Lipan_Apache_lipa1241.csv\n",
      "Cocopa_coco1261.csv\n",
      "Kamano_kama1370.csv\n",
      "Navajo_nava1243.csv\n",
      "Achuar_achu1249.csv\n",
      "Morgan1871_Tabasco_Chontal_(Chontal_Tabasco)_taba1266.csv\n",
      "Berik_beri1254.csv\n",
      "Maybrat_maib1239.csv\n",
      "Korafe_kora1295.csv\n",
      "Marra_mara1385.csv\n",
      "Morgan1871_Winnebagoe_winn1245.csv\n",
      "Morgan1871_Tukuthe_gwic1235.csv\n",
      "Kemiju_(Jate)_keya1238.csv\n",
      "Yalic_yali1257.csv\n",
      "Japanese_nucl1643.csv\n",
      "Ayoreo_ayor1240.csv\n",
      "Iwam_iwam1256.csv\n",
      "Dalabon_ngal1292.csv\n",
      "Duna_duna1248.csv\n",
      "Nyulnyul_nyul1247.csv\n",
      "Morgan1871_Dakota_Brule_brul1239.csv\n",
      "Abui_abui1241.csv\n",
      "Dogrib_dogr1252.csv\n",
      "Ket_kett1243.csv\n",
      "Puinave_puin1248.csv\n",
      "Netsilik_nets1241.csv\n",
      "Southern_Coastal_Tsimshian_nucl1649.csv\n",
      "Foi_foii1241.csv\n",
      "Shasta_shas1239.csv\n",
      "Usurufa_usar1243.csv\n",
      "Suki_suki1245.csv\n",
      "Inanwatan_(Suabo)_inan1242.csv\n",
      "Lardil_lard1243.csv\n",
      "Morgan1871_Cayuga_cayu1261.csv\n",
      "Cayubaba_cayu1262.csv\n",
      "Dene_Suline_chip1261.csv\n",
      "Morgan1871_Crow_crow1244.csv\n",
      "ASF_Auslan_aust1271.csv\n",
      "Umbu-Ungu_umbu1258.csv\n",
      "Morgan1871_Wyandote_wyan1247.csv\n",
      "Warta_Thuntai_gunt1241.csv\n",
      "Meyah_meya1236.csv\n",
      "Maklew_makl1246.csv\n",
      "Meriam_meri1244.csv\n",
      "Deline_nort2942.csv\n",
      "Sanapana_sana1298.csv\n",
      "Galeia_A_gale1259.csv\n",
      "Tuyuca_tuyu1244.csv\n",
      "Moni_moni1261.csv\n",
      "Doutai_dout1240.csv\n",
      "Cubeo_cube1242.csv\n",
      "Morgan1871_Tesuque_tesu1245.csv\n",
      "Kiowa_Apache_kiow1264.csv\n",
      "Western_Pantar_lamm1241.csv\n",
      "Nasioi_naas1242.csv\n",
      "Tidore_(version_1)_tido1248.csv\n",
      "Awa_imbo1238.csv\n",
      "Setaman_Baktamin_seta1246.csv\n",
      "Kiwaian_sout2949.csv\n",
      "Sion_sion1247.csv\n",
      "Waffa_waff1241.csv\n",
      "Morgan1871_Mountain_Cherokee_cher1273.csv\n",
      "Pagu_pagu1249.csv\n",
      "Huli_huli1244.csv\n",
      "Kanum_kanu1280.csv\n",
      "Fore_fore1270.csv\n",
      "Trumai_trum1247.csv\n",
      "Kunza_kunz1244.csv\n",
      "Riantana_rian1263.csv\n",
      "Ketengban_kete1254.csv\n",
      "Morgan1871_Dakota_Isauntie_dako1258.csv\n",
      "Kalamang_kara1499.csv\n",
      "Cha_palaa_chac1249.csv\n",
      "Bardi_bard1254.csv\n",
      "Midob_mido1240.csv\n",
      "Morgan1871_Tuscarora_tusc1257.csv\n",
      "Waorani_waor1240.csv\n",
      "Morgan1871_Slave_Lake_Indians_or_A-cha'o-tin-ne_slav1253.csv\n",
      "Morgan1871_Kootenay_kute1249.csv\n",
      "Toba_toba1269.csv\n",
      "Savosavo_savo1255.csv\n",
      "Wappo_wapp1239.csv\n",
      "Morgan1871_Dakota_Sisseton_dako1258.csv\n",
      "Ende_(Papua_New_Guinea)_ende1235.csv\n",
      "Blagar_blag1240.csv\n",
      "Morgan1871_Two_Mountain_Iroquios_laur1250.csv\n",
      "Wari__wari1268.csv\n",
      "Bilua_bilu1245.csv\n",
      "Baruya_baru1267.csv\n",
      "Rotokas_roto1249.csv\n",
      "Mali_mali1284.csv\n",
      "Maca_maca1260.csv\n",
      "Xibe_xibe1242.csv\n",
      "Nen_nenn1238.csv\n",
      "Tzeltal_tzel1254.csv\n",
      "Yele_(Yeli_Dnye)_yele1255.csv\n",
      "Kung_juho1239.csv\n",
      "Murrinhpatha_murr1258.csv\n",
      "Morgan1871_Choctaw_(2)_choc1276.csv\n",
      "Yawa_nucl1454.csv\n",
      "Gui_(Gwi)_gwii1239.csv\n",
      "Central_Aymara_cent2142.csv\n",
      "Sawi_sawi1257.csv\n",
      "Gununa_Kune_puel1244.csv\n",
      "Teiwa_teiw1235.csv\n",
      "Yanomami_yano1262.csv\n",
      "Lake_Miwok_lake1258.csv\n",
      "Morgan1871_Choctaw_(1)_choc1276.csv\n",
      "Morgan1871_Minnitaree_hida1246.csv\n",
      "Morgan1871_Onondaga_onon1246.csv\n",
      "Nivacle_niva1238.csv\n",
      "Sougb_mani1235.csv\n",
      "Kayardild_kaya1318.csv\n",
      "Kwoma_kwom1262.csv\n",
      "Hewa_hewa1241.csv\n",
      "Limilngan_limi1242.csv\n",
      "Marind_nucl1622.csv\n",
      "Morgan1871_Assiniboine_(Asiniboine)_assi1247.csv\n",
      "Miani_mian1254.csv\n",
      "Kombai_komb1274.csv\n",
      "Watam_wata1253.csv\n",
      "Adang_adan1251.csv\n",
      "Taiap_taia1239.csv\n",
      "Bininj_Kun-wok_gunw1252.csv\n",
      "Konda_(Western_Dani)_west2594.csv\n",
      "Eyak_eyak1241.csv\n",
      "Northwestern_Maidu_nort2951.csv\n",
      "Yuki_yuki1243.csv\n",
      "Amanab_aman1265.csv\n",
      "Klon_kelo1247.csv\n",
      "Touo_touo1238.csv\n",
      "Nama_nama1266.csv\n",
      "Morgan1871_Omaha_omah1247.csv\n",
      "Morgan1871_Cherokee_cher1273.csv\n",
      "Ekari_ekar1243.csv\n",
      "Morgan1871_Dakota_Uncpapa_lako1247.csv\n",
      "Morgan1871_Western_Canadian_Inuktitut_(Eskimo,_West_of_Hudson's_Bay)_west2618.csv\n",
      "Bari_bari1297.csv\n",
      "Idi_nucl1597.csv\n",
      "Lengua_leng1262.csv\n",
      "Tehuelche_tehu1242.csv\n",
      "Jicarilla_jica1244.csv\n",
      "Morgan1871_Red-knife,_or_Tal-sote'e-na_dogr1252.csv\n",
      "Morgan1871_Grand_Pawnee_pawn1254.csv\n",
      "Muisca_Chibcha__chib1270.csv\n",
      "Au_auuu1241.csv\n",
      "Khalkha-Mongolian_mong1331.csv\n",
      "Hunza_hunz1248.csv\n",
      "Copper_Inuit_copp1244.csv\n",
      "Elamite_elam1244.csv\n",
      "Awiakay_awia1234.csv\n",
      "I'saka_(Krisa)_kris1246.csv\n",
      "Tsafiki_colo1249.csv\n",
      "Wersing_wers1238.csv\n",
      "Morgan1871_Dakota_Blackfoot_lako1247.csv\n",
      "Itonama_iton1250.csv\n",
      "Movima_movi1243.csv\n",
      "Yale_kosa1249.csv\n",
      "Yuracare_yura1255.csv\n",
      "Kilmeri_kilm1241.csv\n",
      "Morgan1871_Baffin_Inuktitut_(Eskimo,_Northumberland_Inlet)_baff1241.csv\n",
      "Morgan1871_Dakota_Ogalalla_lako1247.csv\n",
      "Kamang_kama1365.csv\n",
      "Iau_iauu1242.csv\n",
      "Koiari_gras1249.csv\n",
      "Paez_paez1247.csv\n",
      "Basque_west1508.csv\n",
      "Mocovi_moco1246.csv\n",
      "Chimariko_chim1301.csv\n",
      "Monumbo_nucl1458.csv\n",
      "Kiraman_kira1248.csv\n",
      "Ganggalida_gang1267.csv\n",
      "Pume_pume1238.csv\n",
      "Cusco_Quechua_cusc1236.csv\n",
      "Daribi_dadi1250.csv\n",
      "Tolowa_tolo1259.csv\n",
      "Wailaki_wail1244.csv\n",
      "Mapudungun_mapu1245.csv\n",
      "Tucanoan_Bara_waim1255.csv\n",
      "Morgan1871_Laguna_west2632.csv\n",
      "Seri_seri1257.csv\n",
      "Morgan1871_Otoe_otoo1241.csv\n",
      "Cruzeno_cruz1243.csv\n",
      "Yucatec_Maya_yuca1254.csv\n",
      "Neme_neme1244.csv\n",
      "DeneTha_South_Slavey__sout2959.csv\n",
      "Qawasquar_qawa1238.csv\n",
      "Tabla_tabl1243.csv\n",
      "Kogi_cogu1240.csv\n",
      "Morgan1871_Punka_ponc1241.csv\n",
      "Iyojwa_ja_Chorote_iyoj1235.csv\n",
      "Nungon_yaum1237.csv\n",
      "Morgan1871_Chickasa_chic1270.csv\n",
      "Chipaya_chip1262.csv\n",
      "Yamana_yama1264.csv\n",
      "Karok_karo1304.csv\n",
      "Tidore_tido1249.csv\n",
      "Pilaga_pila1245.csv\n",
      "Alamblak_alam1246.csv\n",
      "Northeastern_Maidu_nort2952.csv\n",
      "Negwa_(Yagwoia)_yagw1240.csv\n",
      "Morgan1871_Dakota_Yanktonais_dako1258.csv\n",
      "Wichi_wich1264.csv\n",
      "Morgan1871_Chibcha_(New_Granada)_chib1270.csv\n",
      "Eipo_eipo1242.csv\n",
      "Isirawa_isir1237.csv\n",
      "Hupa_hupa1239.csv\n",
      "NorthMuyu_nort2916.csv\n",
      "Hoti_Yuwana__yuwa1244.csv\n",
      "Wambaya_wamb1258.csv\n",
      "Northern_Haida_nort2938.csv\n",
      "Epena_epen1239.csv\n",
      "Wipi_wipi1242.csv\n",
      "Telefol_tele1256.csv\n",
      "Cofan_cofa1242.csv\n",
      "Nagovisi_sibe1248.csv\n",
      "Selk_nam_onaa1245.csv\n",
      "Loloda-Laba_(Loda)_lolo1264.csv\n",
      "Jingulu_djin1251.csv\n",
      "Mala_mala1294.csv\n",
      "Morgan1871_Seneca_sene1264.csv\n",
      "Morgan1871_Kaw_kans1243.csv\n",
      "Morgan1871_Kalaallisut_(Eskimo,_Greenland)_kala1399.csv\n",
      "Morgan1871_Mohawk_moha1258.csv\n",
      "Kashaya_kash1280.csv\n",
      "Zuni_zuni1245.csv\n",
      "Keyagana_(Jate)_keya1238.csv\n",
      "Aguaruna_agua1253.csv\n",
      "Coastal_Yuki_yuki1243b.csv\n",
      "Quechan_quec1382.csv\n",
      "Morgan1871_Oneida_onei1249.csv\n",
      "Ninam_nina1238.csv\n",
      "Morgan1871_Arikara_(Arickaree)_arik1262.csv\n",
      "Siwai_Motuna_siwa1245.csv\n",
      "Morgan1871_Creek_cree1270.csv\n",
      "Yukulta_(Ganggalida)_gang1267a.csv\n",
      "Galeia_B_gale1259.csv\n",
      "Tidore_(version_2)_tido1248a.csv\n",
      "Morgan1871_Yakama_yaki1237.csv\n",
      "Morgan1871_Kutchin,_or_Louchieux_gwic1235.csv\n",
      "Komnzo_komn1238.csv\n",
      "Atsugewi_atsu1245.csv\n",
      "Basque_basq1248.csv\n",
      "Kuman_kuma1280.csv\n",
      "Kunimaipa_kuni1267.csv\n",
      "Western_Apache_west2615.csv\n",
      "Morgan1871_Dakota_Yankton_dako1258.csv\n",
      "Kewa_east2516.csv\n",
      "Kaure_kaur1271.csv\n",
      "Nambo_namb1293.csv\n",
      "Morgan1871_Iowa_iowa1245.csv\n",
      "Morgan1871_Osage_osag1243.csv\n",
      "Edopi_edop1238.csv\n",
      "Mattole_matt1238.csv\n",
      "Momu-Fas_fass1245.csv\n",
      "Madole_modo1249.csv\n",
      "Degexit_an_dege1248.csv\n",
      "Morgan1871_Mandan_mand1446.csv\n",
      "Chiricahua_mesc1238.csv\n",
      "Korowai_koro1312.csv\n",
      "Onobasulu_onob1238.csv\n",
      "Gimi_gimi1243.csv\n",
      "Northern_Pomo_nort2966.csv\n",
      "Agob-Ende-Kawam_agob1244.csv\n",
      "Northern_Embera_nort2972.csv\n",
      "Morgan1871_Republican_Pawnee_pawn1254.csv\n",
      "Grand_Valley_Dani_lowe1415.csv\n",
      "Yelmek_yelm1242.csv\n",
      "Nen_nenn1238a.csv\n",
      "Nuu_Chah_Nulth_nuuc1236.csv\n",
      "Tucano_tuca1252.csv\n",
      "Dhuwal-Dhuwala_(Yolngu)_dhuw1248.csv\n",
      "Paakantyi_darl1243.csv\n",
      "Malgana_malg1242a.csv\n",
      "Yir-Yoront_yiry1245.csv\n",
      "Wangkangurru_wang1290.csv\n",
      "Wangkangurru_wang1290a.csv\n",
      "Dharumbal_dhar1248a.csv\n",
      "Yadhaykenu_yadh1237.csv\n",
      "Warlpiri_warl1254.csv\n",
      "Gupapuyngu_gupa1247.csv\n",
      "Ngarinyman_ngar1235.csv\n",
      "Karuwali_karr1236.csv\n",
      "Warnman_wanm1242.csv\n",
      "Warumungu_waru1265.csv\n",
      "Thayore_(Kuuk_Thaayorre)_thay1249.csv\n",
      "Wulguru_wulg1239.csv\n",
      "WikMungkan_wikm1247.csv\n",
      "Yarluyandi_ngam1265.csv\n",
      "Arabana_arab1267a.csv\n",
      "Warrnambool_warr1257.csv\n",
      "Adnyamathanha_adny1235.csv\n",
      "Kaurna_kaur1267.csv\n",
      "Yugambal_(Yugambeh)_yuga1244.csv\n",
      "Malgana_malg1242.csv\n",
      "Yulparija_yulp1239.csv\n",
      "Muruwari_muru1266.csv\n",
      "Duungidjawu_duun1241.csv\n",
      "Badimaya_badi1246.csv\n",
      "Ngaanyatjarra_ngaa1240.csv\n",
      "Payungu_bayu1240.csv\n",
      "Ngaatjatjarra_ngaa1240.csv\n",
      "Nhanta_nhan1238.csv\n",
      "Jaru_jaru1254.csv\n",
      "Umpila_umpi1239.csv\n",
      "Kuku-Yalanji_kuku1273.csv\n",
      "Wakaya_waga1260.csv\n",
      "Yandruwandha_yand1253.csv\n",
      "Pitjantjatjara_pitj1243.csv\n",
      "Nyangumarta_nyan1301.csv\n",
      "Diyari_dier1241.csv\n",
      "Kariyarra_kari1304.csv\n",
      "Dyirbal_dyir1250.csv\n",
      "Gunya_guny1241.csv\n",
      "Pitta_Pitta_pitt1247.csv\n",
      "KukuYalanji_kuku1273.csv\n",
      "Wangkajunga_wang1288.csv\n",
      "Djambarrpuyngu_djam1256.csv\n",
      "Yandruwandha_yand1253a.csv\n",
      "Biri_biri1256.csv\n",
      "Wangkumara_wong1246.csv\n",
      "Wiradjuri_wira1262.csv\n",
      "Bindal_bind1236.csv\n",
      "Guugu_Yimidhirr_gugu1255.csv\n",
      "Kala_Lagaw_Ya_kala1377.csv\n",
      "Yindjibarndi_yind1247.csv\n",
      "Margany_marg1253.csv\n",
      "Yugambeh_yugu1249.csv\n",
      "Yalarnnga_yala1262a.csv\n",
      "Djinang_djin1253.csv\n",
      "Kartujarra_kart1247.csv\n",
      "Dhuwal_dhuw1249.csv\n",
      "Diyari_dier1241a.csv\n",
      "Gurindji_guri1247.csv\n",
      "Yalarnnga_yala1262.csv\n",
      "Alyawarr_alya1239.csv\n",
      "Kuuku_Ya'u_kuuk1238.csv\n",
      "Warungu_waru1264.csv\n",
      "PintupiLuritja_pint1250.csv\n",
      "Mudburra_mudb1240.csv\n",
      "Djinang_djin1253a.csv\n",
      "Yidiny_yidi1250.csv\n",
      "Uradhi_(Atampaya)_atam1239.csv\n",
      "Ritharrngu_rita1239.csv\n",
      "Ngiyambaa_wang1291.csv\n",
      "Gumbaynggir_kumb1268.csv\n",
      "Wajarri_waja1257.csv\n",
      "Yidiny_yidi1250a.csv\n",
      "Warlmanpa_warl1255.csv\n",
      "MartuWangka_mart1256.csv\n",
      "Bandjalang_band1339.csv\n",
      "Yuwaalaraay_gami1243.csv\n",
      "Yorta_Yorta_yort1237.csv\n",
      "Ngarluma_ngar1287.csv\n",
      "Nyamal_nyam1271.csv\n",
      "Arabana_arab1267.csv\n",
      "Ngadjumaya_ngad1258.csv\n",
      "Kunjen_kunj1248.csv\n",
      "Kukatja_kuka1246.csv\n",
      "Djapu_dhuw1249.csv\n",
      "Guugu_Yimidhirr_gugu1255a.csv\n",
      "Ngarla_ngar1286.csv\n",
      "Kalkatungu_kalk1246.csv\n",
      "Nyawaygi_nyaw1247.csv\n",
      "Karajarri_kara1476.csv\n",
      "Ngarrindjeri_narr1259.csv\n",
      "Pirriya_pirr1240.csv\n",
      "Wathwurrung_wath1238.csv\n",
      "Warlpiri_warl1254a.csv\n",
      "Dharumbal_dhar1248.csv\n",
      "Wirangu_wira1265.csv\n",
      "Woiwurrung_woiw1237.csv\n",
      "Bunganditj_bung1264.csv\n",
      "Yanyuwa_yany1243.csv\n",
      "Gumatj_guma1253.csv\n",
      "FlindersIsland_flin1247.csv\n",
      "Shipibo_ship1254.csv\n",
      "Morgan1871_Spokane_spok1245.csv\n",
      "Morgan1871_Okinaken_okan1243.csv\n",
      "Morgan1871_Burmese_burm1266.csv\n",
      "Burmese_nucl1310.csv\n",
      "Dzonghka_Wang_wang1287.csv\n",
      "Chepang_chep1245.csv\n",
      "Dzonghka_Sha_dzon1239.csv\n",
      "Morgan1871_Karen_kare1337.csv\n",
      "Dzonghka_Lhop_dzon1239.csv\n",
      "Morgan1871_Chinese_sini1245.csv\n",
      "Morgan1871_Karen_(Pwo_dialect)_pwoo1239.csv\n",
      "Sangtam_Naga_sang1321.csv\n",
      "Suzhou_suzh1234.csv\n",
      "Prakaa_prak1243.csv\n",
      "Suzhou_shan1293.csv\n",
      "Morgan1871_Karen_(Sgau_dialect)_sgaw1245.csv\n",
      "Manange_mana1288.csv\n",
      "Lisu_lisu1250d.csv\n",
      "Sherpa_sher1255.csv\n",
      "Jinghpaw_jing1260.csv\n",
      "Lisu_lisu1250b.csv\n",
      "Lisu_lisu1250c.csv\n",
      "Lisu_lisu1250a.csv\n",
      "Turung_turu1249.csv\n",
      "Dehong_deho1238.csv\n",
      "Tenharim_tenh1241.csv\n",
      "Tapirape_tapi1254.csv\n",
      "Siriono_siri1273.csv\n",
      "Kayabi_kaya1329.csv\n",
      "Mbya_Guarani_mbya1239.csv\n",
      "Pauserna_paus1244.csv\n",
      "Ava_Canoeiro_avac1239.csv\n",
      "Cocama_Cocamilla_coca1259.csv\n",
      "Aweti_awet1244.csv\n",
      "Munduruku_mund1330.csv\n",
      "Arawete_araw1273.csv\n",
      "Tupi_tupi1274.csv\n",
      "Emerillon_emer1243.csv\n",
      "Parakana_para1312.csv\n",
      "Guarayu_guar1292.csv\n",
      "Karitiana_kari1311.csv\n",
      "Kamayura_kama1373.csv\n",
      "Kaiwa_kaiw1246.csv\n",
      "Juruna_juru1256.csv\n",
      "Tupinamba_tupi1273.csv\n",
      "Wayampi_waya1270.csv\n",
      "Anambe_anam1249.csv\n",
      "Paraguayan_Guarani_para1311.csv\n",
      "Surui_suru1262.csv\n",
      "Satere_Mawe_sate1243.csv\n",
      "Guaja_guaj1256.csv\n",
      "Ache_ache1246.csv\n",
      "Proto_Tupi_Guarani_tupi1276.csv\n",
      "Chiriguano_east2555.csv\n",
      "Cinta_Larga_cint1239.csv\n",
      "Tembe_temb1276.csv\n",
      "Tocantins_Asurini_toca1235.csv\n",
      "Nogai_noga1249.csv\n",
      "Kumyk_kumy1244.csv\n",
      "North_Azerbaijani_nort2697.csv\n",
      "Turkish_nucl1301.csv\n",
      "Kazakh_kaza1248.csv\n",
      "Komi_Zyrian_komi1268.csv\n",
      "kinura_KazymKhanty_nort2672.csv\n",
      "Mansi_mans1258.csv\n",
      "kinura_ErzyaMordvin_erzy1239.csv\n",
      "kinura_SosvaMansi_nort2677.csv\n",
      "kinura_SkoltSaami_skol1241.csv\n",
      "Udmurt_udmu1245.csv\n",
      "kinura_MeadowMari_gras1239.csv\n",
      "kinura_SouthSaami_sout2674.csv\n",
      "Veps_veps1250.csv\n",
      "kinura_Livonian_livv1244.csv\n",
      "kinura_TundraNenets_nene1249.csv\n",
      "kinura_MokshaMordvin_moks1248.csv\n",
      "Magyar_hung1274.csv\n",
      "Tundra_Nenets_nene1249.csv\n",
      "Selkup_selk1253.csv\n",
      "kinura_Udmurt_udmu1245.csv\n",
      "kinura_KomiZyrian_komi1268.csv\n",
      "Erzya_erzy1239.csv\n",
      "Finnic_finn1318.csv\n",
      "Mari_east2328.csv\n",
      "kinura_NorthSaami_nort2671.csv\n",
      "Kazym_Berezover_Suryskarer_Khanty_khan1273.csv\n",
      "Estonian_esto1258.csv\n",
      "kinura_Veps_veps1250.csv\n",
      "Ingrian_ingr1248.csv\n",
      "kinura_Finnish_finn1318.csv\n",
      "kinura_ForestEnets_fore1265.csv\n",
      "kinura_Hungarian_hung1274.csv\n",
      "kinura_HillMari_west2392.csv\n",
      "kinura_Nganasan_ngan1291.csv\n",
      "Finnish_finn1318.csv\n",
      "Northern_Sami_nort2671.csv\n",
      "kinura_Estonian_esto1258.csv\n",
      "Bannock_bann1248.csv\n",
      "Pipil_pipi1250.csv\n",
      "Kawaiisu_kawa1283.csv\n",
      "Highland_Puebla_Nahuatl_high1278.csv\n",
      "Southern_Paiute_sout2969.csv\n",
      "Southern_Ute_utee1244.csv\n",
      "Southeastern_Tepehuano_sout2976.csv\n",
      "Huastec_Nahuatl_huas1257.csv\n",
      "Pima_de_Yepachic_chih1238.csv\n",
      "Mayo_mayo1264.csv\n",
      "Tubatulabal_tuba1278.csv\n",
      "Yaqui_yaqu1251.csv\n",
      "Tumpisha_Shoshoni_pana1305.csv\n",
      "Hopi_hopi1249.csv\n",
      "Shoshoni_shos1248.csv\n",
      "Northern_Paiute_nort2954.csv\n",
      "Tohono_O_odham_toho1245.csv\n",
      "Tubar_tuba1279.csv\n",
      "Nevome_pima1248b.csv\n",
      "North_Northern_Paiute_nort1551.csv\n",
      "Western_Shoshoni_west2622.csv\n",
      "Hopi_S__hopi1249b.csv\n",
      "Cupeno_cupe1243.csv\n",
      "Mono_mono1275.csv\n",
      "Gabrielino_tong1329.csv\n",
      "Morgan1871_Utahs_(Tabegwaches)_utes1238.csv\n",
      "Arizona_Yaqui_yaqu1251a.csv\n",
      "Northern_Tepehuan_nort2959.csv\n",
      "Eudeve_eude1234.csv\n",
      "Tarahumara_cent2131.csv\n",
      "Colorado_Ute_utee1244a.csv\n",
      "Opata_opat1246.csv\n",
      "Huichol_huic1243.csv\n",
      "White_Mesa_Ute_utee1244b.csv\n",
      "Kitanemuk_serr1255b.csv\n",
      "Cora_elna1235.csv\n",
      "Serrano_serr1255.csv\n",
      "Guarijio_huar1255.csv\n",
      "Southern_Tepehuan_sout2975.csv\n",
      "Comanche_coma1245.csv\n",
      "Luiseno_luis1253.csv\n",
      "Southern_Tepehuan_W__sout2977.csv\n",
      "Cahuilla_cahu1264.csv\n",
      "Lower_Pima_Pima_Bajo_pima1248.csv\n",
      "Chemehuevi_chem1251.csv\n",
      "Aztec_clas1250.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>language_family</th>\n",
       "      <th>code</th>\n",
       "      <th>simulation_code</th>\n",
       "      <th>simulation</th>\n",
       "      <th>mutual_information</th>\n",
       "      <th>entropy_gn</th>\n",
       "      <th>entropy_gn1</th>\n",
       "      <th>conditional_entropy</th>\n",
       "      <th>variation_gn</th>\n",
       "      <th>variation_gn1</th>\n",
       "      <th>number_of_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Namakura</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>nama1268b</td>\n",
       "      <td>nama1268b_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.49261</td>\n",
       "      <td>2.23593</td>\n",
       "      <td>1.49261</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Woleaian</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>wole1240</td>\n",
       "      <td>wole1240_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>1.91830</td>\n",
       "      <td>1.91830</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nengone</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>neng1238</td>\n",
       "      <td>neng1238_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.69802</td>\n",
       "      <td>1.75343</td>\n",
       "      <td>2.45321</td>\n",
       "      <td>1.75519</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ontong_Java</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>onto1237</td>\n",
       "      <td>onto1237_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.53049</td>\n",
       "      <td>1.53049</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Luiseno</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>luis1253</td>\n",
       "      <td>luis1253_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>1.82193</td>\n",
       "      <td>2.62193</td>\n",
       "      <td>2.62193</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>Cahuilla</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>cahu1264</td>\n",
       "      <td>cahu1264_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>1.63910</td>\n",
       "      <td>2.48346</td>\n",
       "      <td>2.78064</td>\n",
       "      <td>1.14154</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Lower_Pima_Pima_Bajo</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>pima1248</td>\n",
       "      <td>pima1248_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Chemehuevi</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>chem1251</td>\n",
       "      <td>chem1251_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_REAL</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>803 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 language language_family       code simulation_code  \\\n",
       "0                      Sa    Austronesian   saaa1241   saaa1241_REAL   \n",
       "1                Namakura    Austronesian  nama1268b  nama1268b_REAL   \n",
       "2                Woleaian    Austronesian   wole1240   wole1240_REAL   \n",
       "3                 Nengone    Austronesian   neng1238   neng1238_REAL   \n",
       "4             Ontong_Java    Austronesian   onto1237   onto1237_REAL   \n",
       "..                    ...             ...        ...             ...   \n",
       "798              Luiseno     Uto-Aztecan   luis1253   luis1253_REAL   \n",
       "799              Cahuilla     Uto-Aztecan   cahu1264   cahu1264_REAL   \n",
       "800  Lower_Pima_Pima_Bajo     Uto-Aztecan   pima1248   pima1248_REAL   \n",
       "801            Chemehuevi     Uto-Aztecan   chem1251   chem1251_REAL   \n",
       "802                 Aztec     Uto-Aztecan   clas1250   clas1250_REAL   \n",
       "\n",
       "    simulation  mutual_information  entropy_gn  entropy_gn1  \\\n",
       "0            N             0.00000     1.95021      1.00000   \n",
       "1            N             0.49261     2.23593      1.49261   \n",
       "2            N             0.00000    -0.00000      1.91830   \n",
       "3            N             0.69802     1.75343      2.45321   \n",
       "4            N             0.00000     1.00000      1.53049   \n",
       "..         ...                 ...         ...          ...   \n",
       "798          N             1.82193     2.62193      2.62193   \n",
       "799          N             1.63910     2.48346      2.78064   \n",
       "800          N             0.00000    -0.00000      1.00000   \n",
       "801          N             1.00000     1.50000      1.50000   \n",
       "802          N             0.00000     1.00000      1.00000   \n",
       "\n",
       "     conditional_entropy  variation_gn  variation_gn1  number_of_pairs  \n",
       "0                1.00000             4              2                8  \n",
       "1                1.00000             5              3               10  \n",
       "2                1.91830             1              4                4  \n",
       "3                1.75519             5              6               14  \n",
       "4                1.53049             2              3                6  \n",
       "..                   ...           ...            ...              ...  \n",
       "798              0.80000             8              7               13  \n",
       "799              1.14154             7              8               16  \n",
       "800              1.00000             1              2                2  \n",
       "801              0.50000             3              3                4  \n",
       "802              1.00000             2              2                4  \n",
       "\n",
       "[803 rows x 12 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ics_real(families,language_filepath, 'full-kinship-mi-data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1fa7e",
   "metadata": {},
   "source": [
    "And for the simulations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a16cde29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>language_family</th>\n",
       "      <th>code</th>\n",
       "      <th>simulation_code</th>\n",
       "      <th>simulation</th>\n",
       "      <th>mutual_information</th>\n",
       "      <th>entropy_gn</th>\n",
       "      <th>entropy_gn1</th>\n",
       "      <th>conditional_entropy</th>\n",
       "      <th>variation_gn</th>\n",
       "      <th>variation_gn1</th>\n",
       "      <th>number_of_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_0</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_3</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.95021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802995</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_995</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802996</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_996</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802997</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_997</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802998</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_998</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802999</th>\n",
       "      <td>Aztec</td>\n",
       "      <td>Uto-Aztecan</td>\n",
       "      <td>clas1250</td>\n",
       "      <td>clas1250_999</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>803000 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language language_family      code simulation_code simulation  \\\n",
       "0            Sa    Austronesian  saaa1241      saaa1241_0          Y   \n",
       "1            Sa    Austronesian  saaa1241      saaa1241_1          Y   \n",
       "2            Sa    Austronesian  saaa1241      saaa1241_2          Y   \n",
       "3            Sa    Austronesian  saaa1241      saaa1241_3          Y   \n",
       "4            Sa    Austronesian  saaa1241      saaa1241_4          Y   \n",
       "...         ...             ...       ...             ...        ...   \n",
       "802995    Aztec     Uto-Aztecan  clas1250    clas1250_995          Y   \n",
       "802996    Aztec     Uto-Aztecan  clas1250    clas1250_996          Y   \n",
       "802997    Aztec     Uto-Aztecan  clas1250    clas1250_997          Y   \n",
       "802998    Aztec     Uto-Aztecan  clas1250    clas1250_998          Y   \n",
       "802999    Aztec     Uto-Aztecan  clas1250    clas1250_999          Y   \n",
       "\n",
       "        mutual_information  entropy_gn  entropy_gn1  conditional_entropy  \\\n",
       "0                      0.0     1.95021          1.0                  1.0   \n",
       "1                      0.0     1.95021          1.0                  1.0   \n",
       "2                      0.0     1.95021          1.0                  1.0   \n",
       "3                      0.0     1.95021          1.0                  1.0   \n",
       "4                      0.0     1.95021          1.0                  1.0   \n",
       "...                    ...         ...          ...                  ...   \n",
       "802995                 0.0     1.00000          1.0                  1.0   \n",
       "802996                 0.0     1.00000          1.0                  1.0   \n",
       "802997                 0.0     1.00000          1.0                  1.0   \n",
       "802998                 0.0     1.00000          1.0                  1.0   \n",
       "802999                 0.0     1.00000          1.0                  1.0   \n",
       "\n",
       "        variation_gn  variation_gn1  number_of_pairs  \n",
       "0                  4              2                8  \n",
       "1                  4              2                8  \n",
       "2                  4              2                8  \n",
       "3                  4              2                8  \n",
       "4                  4              2                8  \n",
       "...              ...            ...              ...  \n",
       "802995             2              2                4  \n",
       "802996             2              2                4  \n",
       "802997             2              2                4  \n",
       "802998             2              2                4  \n",
       "802999             2              2                4  \n",
       "\n",
       "[803000 rows x 12 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ics_simulation(families,language_filepath,'simulated-kinship-mi-data',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b779e",
   "metadata": {},
   "source": [
    "If we wanted to run a simulation on a single language family:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53d51a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>language_family</th>\n",
       "      <th>code</th>\n",
       "      <th>simulation_code</th>\n",
       "      <th>simulation</th>\n",
       "      <th>mutual_information</th>\n",
       "      <th>entropy_gn</th>\n",
       "      <th>entropy_gn1</th>\n",
       "      <th>conditional_entropy</th>\n",
       "      <th>variation_gn</th>\n",
       "      <th>variation_gn1</th>\n",
       "      <th>number_of_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_0</td>\n",
       "      <td>Y</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>1.950212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_1</td>\n",
       "      <td>Y</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>1.950212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_2</td>\n",
       "      <td>Y</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>1.950212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_3</td>\n",
       "      <td>Y</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>1.950212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sa</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>saaa1241</td>\n",
       "      <td>saaa1241_4</td>\n",
       "      <td>Y</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>1.950212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Takia</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>taki1248</td>\n",
       "      <td>taki1248_5</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.326965e-01</td>\n",
       "      <td>1.356039</td>\n",
       "      <td>1.932112</td>\n",
       "      <td>1.799415</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Takia</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>taki1248</td>\n",
       "      <td>taki1248_6</td>\n",
       "      <td>Y</td>\n",
       "      <td>5.755225e-02</td>\n",
       "      <td>1.325785</td>\n",
       "      <td>1.932112</td>\n",
       "      <td>1.874559</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>Takia</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>taki1248</td>\n",
       "      <td>taki1248_7</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.905052e-02</td>\n",
       "      <td>1.421912</td>\n",
       "      <td>1.932112</td>\n",
       "      <td>1.883061</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>Takia</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>taki1248</td>\n",
       "      <td>taki1248_8</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.010305e-01</td>\n",
       "      <td>1.325785</td>\n",
       "      <td>1.932112</td>\n",
       "      <td>1.831081</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Takia</td>\n",
       "      <td>Austronesian</td>\n",
       "      <td>taki1248</td>\n",
       "      <td>taki1248_9</td>\n",
       "      <td>Y</td>\n",
       "      <td>8.826211e-02</td>\n",
       "      <td>1.325785</td>\n",
       "      <td>1.932112</td>\n",
       "      <td>1.843849</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     language language_family      code simulation_code simulation  \\\n",
       "0          Sa    Austronesian  saaa1241      saaa1241_0          Y   \n",
       "1          Sa    Austronesian  saaa1241      saaa1241_1          Y   \n",
       "2          Sa    Austronesian  saaa1241      saaa1241_2          Y   \n",
       "3          Sa    Austronesian  saaa1241      saaa1241_3          Y   \n",
       "4          Sa    Austronesian  saaa1241      saaa1241_4          Y   \n",
       "...       ...             ...       ...             ...        ...   \n",
       "2045    Takia    Austronesian  taki1248      taki1248_5          Y   \n",
       "2046    Takia    Austronesian  taki1248      taki1248_6          Y   \n",
       "2047    Takia    Austronesian  taki1248      taki1248_7          Y   \n",
       "2048    Takia    Austronesian  taki1248      taki1248_8          Y   \n",
       "2049    Takia    Austronesian  taki1248      taki1248_9          Y   \n",
       "\n",
       "      mutual_information  entropy_gn  entropy_gn1  conditional_entropy  \\\n",
       "0          -2.220446e-16    1.950212     1.000000             1.000000   \n",
       "1          -2.220446e-16    1.950212     1.000000             1.000000   \n",
       "2          -2.220446e-16    1.950212     1.000000             1.000000   \n",
       "3          -2.220446e-16    1.950212     1.000000             1.000000   \n",
       "4          -2.220446e-16    1.950212     1.000000             1.000000   \n",
       "...                  ...         ...          ...                  ...   \n",
       "2045        1.326965e-01    1.356039     1.932112             1.799415   \n",
       "2046        5.755225e-02    1.325785     1.932112             1.874559   \n",
       "2047        4.905052e-02    1.421912     1.932112             1.883061   \n",
       "2048        1.010305e-01    1.325785     1.932112             1.831081   \n",
       "2049        8.826211e-02    1.325785     1.932112             1.843849   \n",
       "\n",
       "      variation_gn  variation_gn1  number_of_pairs  \n",
       "0                4              2                8  \n",
       "1                4              2                8  \n",
       "2                4              2                8  \n",
       "3                4              2                8  \n",
       "4                4              2                8  \n",
       "...            ...            ...              ...  \n",
       "2045             3              4               10  \n",
       "2046             3              4               11  \n",
       "2047             3              4               11  \n",
       "2048             3              4               11  \n",
       "2049             3              4               10  \n",
       "\n",
       "[2050 rows x 12 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ics_simulation(['Austronesian'],family_filepath,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
